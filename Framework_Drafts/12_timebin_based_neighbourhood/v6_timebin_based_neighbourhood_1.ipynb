{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "from timeit import default_timer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeConstraint:\n",
    "    \"\"\"\n",
    "    TimeConstraint is used to as a constraint on the timestamp of the movie ratings.\n",
    "    We classify this TimeConstraints as either max_time_constraint or time_bin constraint\n",
    "    max_time_constraint is used to simulate real life in which we do not know the future but all the data up until one point.\n",
    "    time_bin_constraint is used to grap a portion of a time interval where starting and ending points are strictly defined and data is well known.\n",
    "    \"\"\"\n",
    "    def __init__(self, end_dt, start_dt=None):\n",
    "        \"\"\"\n",
    "        When end_dt is only given, system will have a max time constraint only.\n",
    "\n",
    "        When end_dt and start_dt are given, system will have beginning end ending boundary.\n",
    "\n",
    "        :param end_dt: The maximum limit of the time constraint.\n",
    "        :param start_dt: The minimum limit of the time constraint.\n",
    "            Always set start_dt to None if you change the object from time_bin to max_limit.\n",
    "        \"\"\"\n",
    "        self.end_dt = end_dt\n",
    "        self.start_dt = start_dt\n",
    "\n",
    "    def is_valid_time_bin(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check whether this TimeConstraint object represents a valid time bin.\n",
    "        \"\"\"\n",
    "        if self.is_time_bin() and (self._end_dt > self._start_dt):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_valid_max_limit(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check whether this TimeConstraint represents a valid max time limit.\n",
    "        \"\"\"\n",
    "        if (self._end_dt is not None) and (self._start_dt is None):\n",
    "            return True\n",
    "\n",
    "    def is_time_bin(self) -> bool:\n",
    "        if (self._start_dt is not None) and (self._end_dt is not None):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Comparing TimeConstraints\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self._start_dt == other.start_dt and self._end_dt == other.end_dt\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self._start_dt != other.start_dt or self._end_dt != other.end_dt\n",
    "\n",
    "    # Properties\n",
    "\n",
    "    @property\n",
    "    def end_dt(self):\n",
    "        return self._end_dt\n",
    "\n",
    "    @end_dt.setter\n",
    "    def end_dt(self, value):\n",
    "        self._end_dt = value\n",
    "\n",
    "    @property\n",
    "    def start_dt(self):\n",
    "        return self._start_dt\n",
    "\n",
    "    @start_dt.setter\n",
    "    def start_dt(self, value):\n",
    "        self._start_dt = value\n",
    "\n",
    "    # Printing TimeConstraints\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"(start = {self._start_dt}, end= {self._end_dt})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"(start = {self._start_dt}, end= {self._end_dt})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \"\"\"\n",
    "    Cache is introduced as a way to speed up the bulk analysis. In a normal RecSys, this class should not exist(probably.d).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 is_ratings_cached=False,\n",
    "                 ratings=None,\n",
    "                 is_movies_cached=False,\n",
    "                 movies=None,\n",
    "                 is_movie_ratings_cached=False,\n",
    "                 movie_ratings=None,\n",
    "                 is_user_movie_matrix_cached=False,\n",
    "                 user_movie_matrix=None,\n",
    "                 is_user_correlations_cached=False,\n",
    "                 user_correlations=None,\n",
    "                 min_common_elements=5,\n",
    "                 use_avg_ratings_cache=True):\n",
    "        \"\"\" Cached data is only valid when the boolean specifier is True \"\"\"\n",
    "\n",
    "        # 30% performance\n",
    "        self.is_ratings_cached = is_ratings_cached\n",
    "        self.ratings = ratings\n",
    "\n",
    "        # 7 fold performance gain on 'movie' related queries\n",
    "        self.is_movies_cached = is_movies_cached\n",
    "        self.movies = movies\n",
    "\n",
    "        self.is_movie_ratings_cached = is_movie_ratings_cached\n",
    "        self.movie_ratings = movie_ratings\n",
    "\n",
    "        self.is_user_movie_matrix_cached = is_user_movie_matrix_cached\n",
    "        self.user_movie_matrix = user_movie_matrix\n",
    "\n",
    "        self.is_user_correlations_cached = is_user_correlations_cached\n",
    "        self.user_correlations = user_correlations\n",
    "\n",
    "        self.min_common_elements = min_common_elements\n",
    "\n",
    "        # if use avg ratings cache, on average 10 fold performance gain\n",
    "        self.use_avg_ratings_cache = use_avg_ratings_cache\n",
    "        if self.use_avg_ratings_cache:\n",
    "            self.avg_user_ratings = self.create_user_avg_rating_cache()\n",
    "        else:\n",
    "            self.avg_user_ratings = None\n",
    "\n",
    "    def create_user_avg_rating_cache(self):\n",
    "        if self.is_ratings_cached:\n",
    "            data = self.ratings\n",
    "        else:\n",
    "            data = self.movie_ratings\n",
    "        return data.groupby('user_id')[['rating']].mean()\n",
    "\n",
    "    def get_user_corrs(self, min_common_elements, time_constraint=None):\n",
    "        \"\"\"\n",
    "        If cached returns the cache, else none\n",
    "        :param min_common_elements: min common element in between users in order them to become neighbours\n",
    "        :param time_constraint: used in temporal caches only, None in this context\n",
    "        :return: user correlation matrix if cache found, else None\n",
    "        \"\"\"\n",
    "        if self.is_user_correlations_cached:\n",
    "            if self.min_common_elements == min_common_elements:\n",
    "                return self.user_correlations\n",
    "        return None\n",
    "\n",
    "    # Properties\n",
    "    @property\n",
    "    def ratings(self):\n",
    "        return self._ratings\n",
    "\n",
    "    @ratings.setter\n",
    "    def ratings(self, value):\n",
    "        self._ratings = value\n",
    "\n",
    "    @property\n",
    "    def movies(self):\n",
    "        return self._movies\n",
    "\n",
    "    @movies.setter\n",
    "    def movies(self, value):\n",
    "        self._movies = value\n",
    "\n",
    "    @property\n",
    "    def movie_ratings(self):\n",
    "        return self._movie_ratings\n",
    "\n",
    "    @movie_ratings.setter\n",
    "    def movie_ratings(self, value):\n",
    "        self._movie_ratings = value\n",
    "\n",
    "    @property\n",
    "    def user_movie_matrix(self):\n",
    "        return self._user_movie_matrix\n",
    "\n",
    "    @user_movie_matrix.setter\n",
    "    def user_movie_matrix(self, value):\n",
    "        self._user_movie_matrix = value\n",
    "\n",
    "    @property\n",
    "    def user_correlations(self):\n",
    "        return self._user_correlations\n",
    "\n",
    "    @user_correlations.setter\n",
    "    def user_correlations(self, value):\n",
    "        self._user_correlations = value\n",
    "\n",
    "    @property\n",
    "    def min_common_elements(self):\n",
    "        return self._min_common_elements\n",
    "\n",
    "    @min_common_elements.setter\n",
    "    def min_common_elements(self, value):\n",
    "        self._min_common_elements = value\n",
    "\n",
    "\n",
    "class TemporalCache(Cache):\n",
    "\n",
    "    def __init__(self,\n",
    "                 time_constraint: TimeConstraint,\n",
    "                 is_ratings_cached=False,\n",
    "                 ratings=None,\n",
    "                 is_movies_cached=False,\n",
    "                 movies=None,\n",
    "                 is_movie_ratings_cached=False,\n",
    "                 movie_ratings=None,\n",
    "                 is_user_movie_matrix_cached=False,\n",
    "                 user_movie_matrix=None,\n",
    "                 is_user_correlations_cached=False,\n",
    "                 user_correlations=None,\n",
    "                 min_common_elements=5,\n",
    "                 use_avg_ratings_cache=True,\n",
    "                 use_bulk_corr_cache=True):\n",
    "\n",
    "        super().__init__(is_ratings_cached=is_ratings_cached,\n",
    "                         ratings=ratings,\n",
    "                         is_movies_cached=is_movies_cached,\n",
    "                         movies=movies,\n",
    "                         is_movie_ratings_cached=is_movie_ratings_cached,\n",
    "                         movie_ratings=movie_ratings,\n",
    "                         is_user_movie_matrix_cached=is_user_movie_matrix_cached,\n",
    "                         user_movie_matrix=user_movie_matrix,\n",
    "                         is_user_correlations_cached=is_user_correlations_cached,\n",
    "                         user_correlations=user_correlations,\n",
    "                         min_common_elements=min_common_elements,\n",
    "                         use_avg_ratings_cache=use_avg_ratings_cache)\n",
    "\n",
    "        self.time_constraint = time_constraint\n",
    "        self.use_bulk_corr_cache = use_bulk_corr_cache\n",
    "        self.user_corrs_in_bulk = None\n",
    "\n",
    "    def is_temporal_cache_valid(self):\n",
    "        # No TimeConstraint, valid\n",
    "        if self._time_constraint is None:\n",
    "            return True\n",
    "        # Bin TimeConstraint or Max Limit TimeConstraint, valid\n",
    "        if self._time_constraint.is_valid_time_bin() or self._time_constraint.is_valid_max_limit():\n",
    "            return True\n",
    "        # Else, Not Valid\n",
    "        return False\n",
    "\n",
    "    def get_user_corrs_from_bulk(self, min_common_elements, time_constraint, bin_size):\n",
    "        if ((self.user_corrs_in_bulk is None) or (self.user_corrs_in_bulk is None)\n",
    "                or (time_constraint is None) or self.min_common_elements != min_common_elements):\n",
    "            return None\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return self.user_corrs_in_bulk.get(time_constraint.end_dt.year)\n",
    "\n",
    "        if bin_size == -1:\n",
    "            return None\n",
    "\n",
    "        bins = self.user_corrs_in_bulk.get(bin_size)\n",
    "        if bins is not None:\n",
    "            return bins.get(time_constraint.start_dt.year)\n",
    "\n",
    "    def get_user_corrs(self, min_common_elements, time_constraint=None):\n",
    "        \"\"\"\n",
    "        If cached returns the cache, else none\n",
    "\n",
    "        :param min_common_elements: min common element in between users in order them to become neighbours\n",
    "        :param time_constraint: time constraint on user correlations\n",
    "        :return: user correlation matrix if cache found, else None\n",
    "        \"\"\"\n",
    "        if self.is_user_correlations_cached:\n",
    "            if self.time_constraint == time_constraint and self.min_common_elements == min_common_elements:\n",
    "                return self.user_correlations\n",
    "        return None\n",
    "\n",
    "    def set_user_corrs(self, user_corrs, min_common_elements, time_constraint):\n",
    "        # Only set when caching is open for user_correlations\n",
    "        if self.is_user_correlations_cached:\n",
    "            self._time_constraint = time_constraint\n",
    "            self.min_common_elements = min_common_elements\n",
    "            self.user_correlations = user_corrs\n",
    "\n",
    "    @property\n",
    "    def time_constraint(self):\n",
    "        return self._time_constraint\n",
    "\n",
    "    @time_constraint.setter\n",
    "    def time_constraint(self, value):\n",
    "        self._time_constraint = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "    \"\"\"\n",
    "    Accuracy class provides utility methods in order to measure accuracy of our analysis.\n",
    "    \n",
    "    rmse, accuracy, balanced accuracy, informedness, markedness, \n",
    "    f1, mcc, precision, recall, specificity \n",
    "    and NPV are currently supported measures as well some threshold measures\n",
    "    where we round ratings less than 3.5 to min rating, upper to max rating and use supported measures on this data.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def rmse(predictions) -> float:\n",
    "        if type(predictions) is pd.DataFrame:\n",
    "            number_of_predictions = 0\n",
    "            sum_of_square_differences = 0.0\n",
    "            for row in predictions.itertuples(index=False):\n",
    "                # row[1] : actual rating, row[0] : prediction\n",
    "                prediction = row[0]\n",
    "                if prediction != 0:\n",
    "                    actual = Accuracy.half_round_rating(row[1])\n",
    "                    prediction = Accuracy.half_round_rating(prediction)\n",
    "                    \n",
    "                    sum_of_square_differences += (actual - prediction) ** 2\n",
    "                    number_of_predictions += 1\n",
    "            return sum_of_square_differences / number_of_predictions if number_of_predictions != 0 else 0\n",
    "        elif type(predictions) is list:\n",
    "            number_of_predictions = 0\n",
    "            sum_of_square_differences = 0.0\n",
    "            for prediction, actual in predictions:\n",
    "                if prediction != 0:\n",
    "                    actual = Accuracy.half_round_rating(actual)\n",
    "                    prediction = Accuracy.half_round_rating(prediction)\n",
    "                    \n",
    "                    sum_of_square_differences += (actual - prediction) ** 2\n",
    "                    number_of_predictions += 1\n",
    "                \n",
    "            if number_of_predictions == 0:\n",
    "                return 0\n",
    "            rmse_value = sum_of_square_differences / number_of_predictions \n",
    "            return rmse_value if rmse_value != 0 else 0.001    # for detecting 0 errors, assume error is 0.001\n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def threshold_accuracy(predictions) -> float:\n",
    "        if type(predictions) is pd.DataFrame:\n",
    "            number_of_predictions = 0\n",
    "            number_of_hit = 0\n",
    "            for row in predictions.itertuples(index=False):\n",
    "                # row[1] : actual rating, row[0] : prediction\n",
    "                prediction = row[0]\n",
    "                if prediction != 0:\n",
    "                    actual = Accuracy.threshold_round_rating(row[1])\n",
    "                    prediction = Accuracy.threshold_round_rating(prediction)\n",
    "                    \n",
    "                    if actual == prediction:\n",
    "                        number_of_hit += 1\n",
    "                    number_of_predictions += 1\n",
    "            return (number_of_hit / number_of_predictions)*100 if number_of_predictions != 0 else 0\n",
    "        elif type(predictions) is list:            \n",
    "            number_of_predictions = 0\n",
    "            number_of_hit = 0\n",
    "            for prediction, actual in predictions:\n",
    "                if prediction != 0:\n",
    "                    actual = Accuracy.threshold_round_rating(actual)\n",
    "                    prediction = Accuracy.threshold_round_rating(prediction)\n",
    "                    \n",
    "                    if actual == prediction:\n",
    "                        number_of_hit += 1\n",
    "                        \n",
    "                    number_of_predictions += 1\n",
    "            return (number_of_hit / number_of_predictions)*100 if number_of_predictions != 0 else 0\n",
    "        return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def threshold_analize(predictions):\n",
    "        TP, FN, FP, TN = Accuracy.threshold_confusion_matrix(predictions)\n",
    "        precision = Accuracy.precision(TP, FP)     # also called PPV\n",
    "        recall = Accuracy.recall(TP, FN)           # also called TPR\n",
    "        specificity = Accuracy.specificity(FP, TN) # also called TNR\n",
    "        NPV = Accuracy.negative_predictive_value(FN, TN)\n",
    "        \n",
    "        accuracy = Accuracy.accuracy(TP, FN, FP, TN)\n",
    "        balanced_accuracy = Accuracy.balanced_accuracy(TPR=recall, TNR=specificity)\n",
    "        informedness = Accuracy.informedness(TPR=recall, TNR=specificity)\n",
    "        markedness = Accuracy.markedness(PPV=precision, NPV=NPV)\n",
    "        \n",
    "        f1 = Accuracy.f_measure(precision, recall)\n",
    "        mcc = Accuracy.mcc(TP, FN, FP, TN)\n",
    "        \n",
    "                \n",
    "        output = {\n",
    "                  \"accuracy\"         :round(accuracy, 3),\n",
    "                  \"balanced_accuracy\":round(balanced_accuracy, 3),\n",
    "                  \"informedness\"     :round(informedness, 3),\n",
    "                  \"markedness\"       :round(markedness, 3),\n",
    "                  \"f1\"               :round(f1, 3),\n",
    "                  \"mcc\"              :round(mcc, 3),\n",
    "                  \"precision\"        :round(precision, 3),\n",
    "                  \"recall\"           :round(recall, 3),\n",
    "                  \"specificity\"      :round(specificity, 3),\n",
    "                  \"NPV\"              :round(NPV, 3)\n",
    "                 }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def analize(predictions):\n",
    "        \"\"\"\n",
    "\n",
    "        https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "        \n",
    "        Returns analysis for each class as list\n",
    "        :return: accuracy, balanced_accuracy, informedness, markedness, f1, mcc, precision, recall, specificity, NPV\n",
    "        \"\"\"\n",
    "        confusion_mtr = Accuracy.confusion_matrix(predictions)\n",
    "        \n",
    "        # Use macro averaging (https://stats.stackexchange.com/questions/187768/matthews-correlation-coefficient-with-multi-class)\n",
    "        precision = [0] * 10 \n",
    "        recall = [0] * 10 \n",
    "        specificity = [0] * 10\n",
    "        NPV = [0] * 10 \n",
    "        \n",
    "        accuracy = [0] * 10 \n",
    "        balanced_accuracy = [0] * 10 \n",
    "        informedness = [0] * 10 \n",
    "        markedness = [0] * 10 \n",
    "        \n",
    "        f1 = [0] * 10 \n",
    "        mcc = [0] * 10\n",
    "        \n",
    "        for i in range(0, 10):\n",
    "            TP, FN, FP, TN = Accuracy.confusion_matrix_one_against_all(confusion_mtr, i)\n",
    "            precision[i] = Accuracy.precision(TP, FP)     # also called PPV\n",
    "            recall[i] = Accuracy.recall(TP, FN)           # also called TPR\n",
    "            specificity[i] = Accuracy.specificity(FP, TN) # also called TNR\n",
    "            NPV[i] = Accuracy.negative_predictive_value(FN, TN)\n",
    "\n",
    "            accuracy[i] = Accuracy.accuracy(TP, FN, FP, TN)\n",
    "            balanced_accuracy[i] = Accuracy.balanced_accuracy(TPR=recall[i], TNR=specificity[i])\n",
    "            informedness[i] = Accuracy.informedness(TPR=recall[i], TNR=specificity[i])\n",
    "            markedness[i] = Accuracy.markedness(PPV=precision[i], NPV=NPV[i])\n",
    "\n",
    "            f1[i] = Accuracy.f_measure(precision[i], recall[i])\n",
    "            mcc[i] = Accuracy.mcc(TP, FN, FP, TN)\n",
    "        \n",
    "        output = {\n",
    "                  \"accuracy\"         :Accuracy.round_list_elements(accuracy, 3),\n",
    "                  \"balanced_accuracy\":Accuracy.round_list_elements(balanced_accuracy, 3),\n",
    "                  \"informedness\"     :Accuracy.round_list_elements(informedness, 3),\n",
    "                  \"markedness\"       :Accuracy.round_list_elements(markedness, 3),\n",
    "                  \"f1\"               :Accuracy.round_list_elements(f1, 3),\n",
    "                  \"mcc\"              :Accuracy.round_list_elements(mcc, 3),\n",
    "                  \"precision\"        :Accuracy.round_list_elements(precision, 3),\n",
    "                  \"recall\"           :Accuracy.round_list_elements(recall, 3),\n",
    "                  \"specificity\"      :Accuracy.round_list_elements(specificity, 3),\n",
    "                  \"NPV\"              :Accuracy.round_list_elements(NPV, 3)\n",
    "                 }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def round_list_elements(l, precision):\n",
    "        \"\"\"\n",
    "        :param l: list of floats\n",
    "        :param precision: precision after dot\n",
    "        \"\"\"\n",
    "        return [ round(x, precision) for x in l ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy_multi_class(confusion_mtr):\n",
    "        length = len(confusion_mtr)\n",
    "        numenator = 0\n",
    "        denuminator = 0 \n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                temp = confusion_mtr[i][j]\n",
    "                denuminator += temp\n",
    "                if i == j:\n",
    "                    numenator += temp\n",
    "        return numenator / denominator\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(TP, FN, FP, TN):\n",
    "        return  (TP + TN) / (TP + FN + FP + TN)\n",
    "    \n",
    "    @staticmethod\n",
    "    def balanced_accuracy(TPR, TNR):\n",
    "        \"\"\"\n",
    "        :param TPR : True Positive Rate or recall or sensitivity\n",
    "        :param TNR : True Negative Rate or specificity or  selectivity\n",
    "        \"\"\"\n",
    "        return (TPR + TNR) / 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def informedness(TPR, TNR):\n",
    "        \"\"\"\n",
    "        :param TPR : True Positive Rate or recall or sensitivity\n",
    "        :param TNR : True Negative Rate or specificity or  selectivity\n",
    "        \"\"\"\n",
    "        return TPR + TNR - 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def markedness(PPV, NPV):\n",
    "        \"\"\"\n",
    "        :param PPV: Positive Predictive Value also known as precision\n",
    "        :param NPV: Negative Predictive Value\n",
    "        \"\"\"\n",
    "        return PPV + NPV - 1 \n",
    "    \n",
    "    @staticmethod\n",
    "    def precision(TP, FP):\n",
    "        \"\"\"\n",
    "        Also called as precision or positive predictive value (PPV)\n",
    "        \n",
    "        Precision = TP / (TP + FP) for binary class\n",
    "        Precision = TP / (All Predicted Positive) for multi class\n",
    "        \"\"\"\n",
    "        denuminator = TP + FP\n",
    "        return TP / denuminator if denuminator != 0 else 0\n",
    "\n",
    "    @staticmethod\n",
    "    def negative_predictive_value(FN, TN):\n",
    "        \"\"\"     \n",
    "        NPV = TN / (TN + FN) for binary class\n",
    "        NPV = TN / (All Predicted Negative) for multi class\n",
    "        \"\"\"\n",
    "        denuminator = TN + FN\n",
    "        return TN / denuminator if denuminator != 0 else 0    \n",
    "    \n",
    "    @staticmethod\n",
    "    def recall(TP, FN):\n",
    "        \"\"\"\n",
    "        Also called as sensitivity, recall, hitrate, or true positive rate(TPR)\n",
    "        Recall = TP / (TP + FN) for binary class\n",
    "        Recall = TP / (All Actual Positive) for multi class\n",
    "        \"\"\"\n",
    "        denuminator = TP + FN\n",
    "        return TP / denuminator if denuminator != 0 else 0    \n",
    "    \n",
    "    @staticmethod\n",
    "    def specificity(FP, TN):\n",
    "        \"\"\"\n",
    "        Also called as specificity, selectivity or true negative rate (TNR)\n",
    "        specificity = TN / (TP + FN) for binary class\n",
    "        specificity = TN / (All Actual Negative) for multi class\n",
    "        \"\"\"\n",
    "        denuminator = FP + TN \n",
    "        return TN / denuminator if denuminator != 0 else 0 \n",
    "    \n",
    "    @staticmethod\n",
    "    def f_measure(precision, recall):\n",
    "        \"\"\"\n",
    "        F-Measure is the harmonic mean of the precision and recall.\n",
    "        \"\"\"\n",
    "        sum_of_both = precision + recall\n",
    "        return (2 * precision * recall) / sum_of_both if sum_of_both != 0 else 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def mcc(TP, FN, FP, TN):\n",
    "        \"\"\"\n",
    "        MCC(Matthews Correlation Coefficient)\n",
    "        \"\"\"\n",
    "        # Calulate Matthews Correlation Coefficient\n",
    "        numenator   = (TP * TN) - (FP * FN) \n",
    "        denominator = (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)\n",
    "        denominator = math.sqrt(denominator) if denominator > 0 else 0\n",
    "        return numenator / denominator if denominator != 0 else 0\n",
    "  \n",
    "# deprecated -> now, we use macro averaging instad of multi class versions of metrics\n",
    "#     @staticmethod\n",
    "#     def mcc_multi_class(confusion_mtr):\n",
    "#         # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient#Multiclass_case\n",
    "#         # https://stats.stackexchange.com/questions/187768/matthews-correlation-coefficient-with-multi-class\n",
    "#         length = len(confusion_mtr)\n",
    "#         numenator = 0\n",
    "#         for k in range(length):\n",
    "#             for l in range(length):\n",
    "#                 for m in range(length):\n",
    "#                     numenator += confusion_mtr[k][k] * confusion_mtr[l][m]\n",
    "#                     numenator -= confusion_mtr[k][l] * confusion_mtr[m][k]\n",
    "\n",
    "#         denuminator_1 = 0\n",
    "#         for k in range(length):\n",
    "#             denuminator_part_1 = 0\n",
    "#             for l in range(length):\n",
    "#                 denuminator_part_1 += confusion_mtr[k][l]\n",
    "\n",
    "#             denuminator_part_2 = 0\n",
    "#             for f in range(length):\n",
    "#                 if f != k:\n",
    "#                     for g in range(length):\n",
    "#                         denuminator_part_2 += confusion_mtr[f][g]\n",
    "#             denuminator_1 += denuminator_part_1 * denuminator_part_2\n",
    "\n",
    "#         denuminator_2 = 0\n",
    "#         for k in range(length):\n",
    "#             denuminator2_part_1 = 0\n",
    "#             for l in range(length):\n",
    "#                 denuminator2_part_1 += confusion_mtr[l][k]\n",
    "\n",
    "#             denuminator2_part_2 = 0\n",
    "#             for f in range(length):\n",
    "#                 if f != k:\n",
    "#                     for g in range(length):\n",
    "#                         denuminator2_part_2 += confusion_mtr[g][f]\n",
    "#             denuminator_2 += denuminator2_part_1 * denuminator2_part_2\n",
    "#         return numenator / math.sqrt(denuminator_1) * math.sqrt(denuminator_2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix_one_against_all(confusion_mtr, class_i):\n",
    "        \"\"\"\n",
    "        Create binary confusion matrix out of multi-class confusion matrix\n",
    "        \n",
    "        Positive Class: class_i\n",
    "        Negative Class: non class_i\n",
    "                \n",
    "        TP: True Positive   FN: False Negative\n",
    "        FP: False Positive  TN: True Negative\n",
    "        \n",
    "        \"TP of Class_1\" is all Class_1 instances that are classified as Class_1.\n",
    "        \"TN of Class_1\" is all non-Class_1 instances that are not classified as Class_1.\n",
    "        \"FP of Class_1\" is all non-Class_1 instances that are classified as Class_1.\n",
    "        \"FN of Class_1\" is all Class_1 instances that are not classified as Class_1.\n",
    "        # https://www.researchgate.net/post/How_do_you_measure_specificity_and_sensitivity_in_a_multiple_class_classification_problem\n",
    "        \n",
    "        --> Input matrix\n",
    "                 | 0 Prediction | 1 Prediction | 2 Prediction | .....\n",
    "        0 Class  |     T0       |     ..       |      ..      |\n",
    "        1 Class  |     ..       |     T1       |      ..      | \n",
    "        2 Class  |     ..       |     ..       |      T2      |\n",
    "        \n",
    "        --> Output matrix\n",
    "        \n",
    "                        | Positive Prediction | Negative Prediction\n",
    "        Positive Class  |       TP            |       FN\n",
    "        Negative Class  |       FP            |       TN\n",
    "        \n",
    "        :param confusion_mtr: 10 class confusion matrix designed for movielens\n",
    "        :param class_i: index of the class we are interested in(0-9)\n",
    "        :return: TP, FN, FP, TN\n",
    "        \"\"\"\n",
    "        length = len(confusion_mtr)\n",
    "\n",
    "        TP = confusion_mtr[class_i][class_i] \n",
    "        \n",
    "        actual_class_i_count = 0 \n",
    "        for i in range(length):  # sum of the row\n",
    "            actual_class_i_count += confusion_mtr[class_i][i]\n",
    "        FN = actual_class_i_count - TP\n",
    "        \n",
    "        predicted_class_i_count = 0\n",
    "        for i in range(length): # sum of the column\n",
    "            predicted_class_i_count += confusion_mtr[i][class_i]\n",
    "        FP = predicted_class_i_count - TP\n",
    "        \n",
    "        # sum of matrix\n",
    "        sum_of_matrix = np.sum(confusion_mtr)\n",
    "        # TN is found by summing up all values except the row and column of the class \n",
    "        TN = sum_of_matrix - predicted_class_i_count - actual_class_i_count - TP \n",
    "        \n",
    "        return TP, FN, FP, TN\n",
    "        \n",
    "    @staticmethod\n",
    "    def confusion_matrix(predictions):\n",
    "        \"\"\"\n",
    "        Create confusion matrix and then return TP, FN, FP, TN\n",
    "\n",
    "        0 Class: 0.5\n",
    "        1 Class: 1\n",
    "        2 Class: 1.5\n",
    "        3 Class: 2\n",
    "        4 Class: 2.5\n",
    "        5 Class: 3\n",
    "        6 Class: 3.5\n",
    "        7 Class: 4\n",
    "        8 Class: 4.5\n",
    "        9 Class: 5\n",
    "\n",
    "        T0: True 0\n",
    "        F0: False 0\n",
    "        T1: True 1\n",
    "        F1: False 1\n",
    "        ...\n",
    "\n",
    "                 | 0 Prediction | 1 Prediction | 2 Prediction | .....\n",
    "        0 Class  |     T0       |     ..       |      ..      |\n",
    "        1 Class  |     ..       |     T1       |      ..      | \n",
    "        2 Class  |     ..       |     ..       |      T2      |\n",
    "        ...\n",
    "        \"\"\"\n",
    "        # Create multiclass confusion matrix\n",
    "\n",
    "        conf_mtr = np.zeros( (10,10) )\n",
    "\n",
    "        for prediction in predictions:\n",
    "            predicted = Accuracy.half_round_rating(prediction[0])\n",
    "            actual    = Accuracy.half_round_rating(prediction[1])\n",
    "\n",
    "            predicted_class_index = int( (predicted * 2) - 1 )\n",
    "            actual_class_index = int( (actual * 2) - 1 )\n",
    "\n",
    "            conf_mtr[actual_class_index][predicted_class_index] += 1\n",
    "\n",
    "        return conf_mtr\n",
    "    \n",
    "    @staticmethod\n",
    "    def threshold_confusion_matrix(predictions):\n",
    "        \"\"\"\n",
    "        Create confusion matrix and then return TP, FN, FP, TN\n",
    "\n",
    "        Positive Class: 5\n",
    "        Negative Class: 0.5\n",
    "\n",
    "        TP: True Positive\n",
    "        TN: True Negative\n",
    "        FP: False Positive\n",
    "        FN: False Negative\n",
    "\n",
    "                        | Positive Prediction | Negative Prediction\n",
    "        Positive Class  |       TP            |       FN\n",
    "        Negative Class  |       FP            |       TN\n",
    "\n",
    "        \"\"\"\n",
    "        # Create confusion matrix\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for prediction in predictions:\n",
    "            predicted = Accuracy.threshold_round_rating(prediction[0])\n",
    "            actual = Accuracy.threshold_round_rating(prediction[1])\n",
    "            if predicted == 5 and actual == 5:\n",
    "                TP += 1\n",
    "            elif predicted == 5 and actual == 0.5:\n",
    "                FP += 1\n",
    "            elif predicted == 0.5 and actual == 0.5:\n",
    "                TN += 1\n",
    "            elif predicted == 0.5 and actual == 5:\n",
    "                FN += 1\n",
    "        return TP, FN, FP, TN\n",
    "\n",
    "    @staticmethod\n",
    "    def half_round_rating(rating):\n",
    "        \"\"\"\n",
    "        Round ratings to the closest match in the movielens dataset\n",
    "        For ex.\n",
    "          ratings between 2 and 2.25 -> round to 2\n",
    "          ratings between 2.25 and 2.5 -> round to 2.5\n",
    "          ratings between 2.5 and 2.75 -> round to 2.5\n",
    "          ratings between 2.75 and 3 -> round to 3\n",
    "\n",
    "        \"\"\"\n",
    "        floor_value = math.floor(rating)\n",
    "        if(rating > floor_value + 0.75):\n",
    "            return floor_value + 1\n",
    "        elif(rating > floor_value + 0.5 or rating > floor_value + 0.25):\n",
    "            return floor_value + 0.5\n",
    "        else:\n",
    "            return floor_value\n",
    "    \n",
    "    @staticmethod\n",
    "    def threshold_round_rating(rating):\n",
    "        \"\"\"\n",
    "        Round ratings to the closest match in threshold fashion\n",
    "          ratings between 0.5 and 2.25 -> round to 0.5\n",
    "          ratings between 2.25 and 5 -> round to 5\n",
    "        \"\"\"\n",
    "        if (0.5 <= rating < 3.5):\n",
    "            return 0.5\n",
    "        elif (3.5 <= rating <= 5):\n",
    "            return 5\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(ABC):\n",
    "    \"\"\"\n",
    "    Dataset class and its subclasses provides utilities in order to import datasets.\n",
    "    \n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def load():\n",
    "        \"\"\" Every subclass must provide static load method\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp'),\n",
    "                 ratings_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv',\n",
    "                 movies_col_names=('item_id', 'title', 'genres'),\n",
    "                 movies_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv',\n",
    "                 is_ratings_cached=True,\n",
    "                 is_movies_cached=True):\n",
    "        Dataset.__init__(self)\n",
    "        self.is_ratings_cached = is_ratings_cached\n",
    "        self.is_movies_cached = is_movies_cached\n",
    "        self.ratings = MovieLensDataset.load_ratings(ratings_path,\n",
    "                                                     ratings_col_names) if self.is_ratings_cached else None\n",
    "        self.movies = MovieLensDataset.load_movies(movies_path,\n",
    "                                                   movies_col_names) if self.is_movies_cached else None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_movies(movies_path,\n",
    "                    movies_col_names=('item_id', 'title', 'genres')):\n",
    "        if not os.path.isfile(movies_path) or not movies_col_names:\n",
    "            return None\n",
    "\n",
    "        # read movies\n",
    "        movies = pd.read_csv(movies_path, sep=',', header=1, names=movies_col_names)\n",
    "\n",
    "        # Extract Movie Year\n",
    "        movies['year'] = movies.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "        movies.year = pd.to_datetime(movies.year, format='%Y')\n",
    "        movies.year = movies.year.dt.year  # As there are some NaN years, resulting type will be float (decimals)\n",
    "\n",
    "        # Remove year part from the title\n",
    "        movies.title = movies.title.str[:-7]\n",
    "\n",
    "        return movies\n",
    "\n",
    "    @staticmethod\n",
    "    def load_ratings(ratings_path,\n",
    "                     ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp')):\n",
    "        if not os.path.isfile(ratings_path) or not ratings_col_names:\n",
    "            return None\n",
    "\n",
    "        # read ratings\n",
    "        ratings = pd.read_csv(ratings_path, sep=',', header=1, names=ratings_col_names)\n",
    "\n",
    "        # Convert timestamp into readable format\n",
    "        ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s', origin='unix')\n",
    "\n",
    "        return ratings\n",
    "\n",
    "    @staticmethod\n",
    "    def create_movie_ratings(ratings, movies):\n",
    "        return pd.merge(ratings, movies, on='item_id')\n",
    "\n",
    "    @staticmethod\n",
    "    def load(ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp'),\n",
    "             ratings_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv',\n",
    "             movies_col_names=('item_id', 'title', 'genres'),\n",
    "             movies_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv'\n",
    "             ):\n",
    "        # Load movies\n",
    "        movies = MovieLensDataset.load_movies(movies_path=movies_path, movies_col_names=movies_col_names)\n",
    "        # Load ratings\n",
    "        ratings = MovieLensDataset.load_ratings(ratings_path=ratings_path, ratings_col_names=ratings_col_names)\n",
    "\n",
    "        # Merge the ratings and movies\n",
    "        movie_ratings = pd.merge(ratings, movies, on='item_id')\n",
    "\n",
    "        return movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalPearson:\n",
    "    \"\"\"\n",
    "    Temporal pearson is the classic way of handling recommendations. \n",
    "    We provide pearson method and related cache support in this class for bulk analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, cache: TemporalCache, time_constraint: TimeConstraint = None, min_common_elements: int = 5):\n",
    "        self.time_constraint = time_constraint\n",
    "        self.cache = cache\n",
    "        self.min_common_elements = min_common_elements\n",
    "        #from .trainset import TrainsetUser, TrainsetMovie\n",
    "        self.trainset_user = TrainsetUser(cache=self.cache)\n",
    "        self.trainset_movie = TrainsetMovie(cache=self.cache)\n",
    "\n",
    "    def mean_centered_pearson(self, user_id, movie_id, k_neighbours: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Mean Centered Prediction\n",
    "\n",
    "        :param user_id: user of interest\n",
    "        :param movie_id: the movie's rating is the one we we want to predict\n",
    "        :param k_neighbours: k nearest neighbours in DataFrame where index user_id, column correlation in between.\n",
    "        :return: Prediction rating\n",
    "        \"\"\"\n",
    "        # If a movie with movie_id not exists, predict 0\n",
    "        if self.trainset_movie.get_movie(movie_id=movie_id).empty:\n",
    "            return 0\n",
    "\n",
    "        if k_neighbours is None or k_neighbours.empty:\n",
    "            return 0\n",
    "\n",
    "        user_avg_rating = self.trainset_user.get_user_avg(user_id=user_id)\n",
    "\n",
    "        weighted_sum = 0.0\n",
    "        sum_of_weights = 0.0\n",
    "        for neighbour_id, data in k_neighbours.iterrows():\n",
    "            # Get each neighbour's correlation 'user_id' and her rating to 'movie_id'\n",
    "            neighbour_corr = data['correlation']\n",
    "            neighbour_rating = self.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=neighbour_id)\n",
    "            # If the neighbour doesnt give rating to the movie_id, pass this around of the loop\n",
    "            if neighbour_rating == 0:\n",
    "                continue\n",
    "            neighbour_avg_rating = self.trainset_user.get_user_avg(user_id=neighbour_id)\n",
    "            neighbour_mean_centered_rating = neighbour_rating - neighbour_avg_rating\n",
    "            # Calculate Weighted sum and sum of weights\n",
    "            weighted_sum += neighbour_mean_centered_rating * neighbour_corr\n",
    "            sum_of_weights += neighbour_corr\n",
    "\n",
    "        # Predict\n",
    "        if sum_of_weights != 0:\n",
    "            prediction_rating = user_avg_rating + (weighted_sum / sum_of_weights)\n",
    "        else:\n",
    "            prediction_rating = 0  # In this case, none of the neighbours have given rating to 'the movie'\n",
    "\n",
    "        return prediction_rating\n",
    "\n",
    "    def get_corr_matrix(self, bin_size=-1):\n",
    "        user_corrs = None\n",
    "        # if valid cache found, try to get user corrs from there\n",
    "        if self.cache.is_temporal_cache_valid():\n",
    "            # First check user-correlations\n",
    "            user_corrs = self.cache.get_user_corrs(self.min_common_elements, self.time_constraint)\n",
    "            if user_corrs is not None:\n",
    "                return user_corrs\n",
    "            # Then check bulk-user-correlations\n",
    "            user_corrs = self.cache.get_user_corrs_from_bulk(time_constraint=self.time_constraint,\n",
    "                                                             min_common_elements=self.min_common_elements,\n",
    "                                                             bin_size=bin_size)\n",
    "            if user_corrs is not None:\n",
    "                return user_corrs\n",
    "\n",
    "        # here, if cache not found or no cache match\n",
    "\n",
    "        # Create user correlations\n",
    "        user_corrs = TemporalPearson.create_user_corrs(movie_ratings=self.cache.movie_ratings,\n",
    "                                                       time_constraint=self.time_constraint,\n",
    "                                                       min_common_elements=self.min_common_elements)\n",
    "        # Cache the user_corrs\n",
    "        self.cache.set_user_corrs(user_corrs=user_corrs,\n",
    "                                  min_common_elements=self.min_common_elements,\n",
    "                                  time_constraint=self.time_constraint)\n",
    "\n",
    "        return user_corrs\n",
    "\n",
    "    @staticmethod\n",
    "    def create_user_corrs(movie_ratings, time_constraint: TimeConstraint, min_common_elements):\n",
    "        # by default movie_ratings is for no time constraint\n",
    "        # with these controls change the time constraint of the movie_ratings\n",
    "        if time_constraint is not None:\n",
    "            if time_constraint.is_valid_max_limit():\n",
    "                movie_ratings = movie_ratings[movie_ratings.timestamp < time_constraint.end_dt]\n",
    "            elif time_constraint.is_valid_time_bin():\n",
    "                movie_ratings = movie_ratings[(movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                              & (movie_ratings.timestamp < time_constraint.end_dt)]\n",
    "\n",
    "        user_movie_matrix = movie_ratings.pivot_table(index='title', columns='user_id', values='rating')\n",
    "        return user_movie_matrix.corr(method=\"pearson\", min_periods=min_common_elements)\n",
    "\n",
    "    def cache_user_corrs_in_bulk_for_max_limit(self, time_constraint: TimeConstraint, min_year, max_year):\n",
    "        \"\"\"\n",
    "        Cache user correlations by changing year of the time_constraint\n",
    "        for each year in between min_year and max_year(not included)\n",
    "\n",
    "        :param time_constraint: time_constraint apply\n",
    "        :param min_year: start of the range\n",
    "        :param max_year: end of the range\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.use_bulk_corr_cache:\n",
    "            if time_constraint is not None and time_constraint.is_valid_max_limit():\n",
    "                self.cache.user_corrs_in_bulk = dict()\n",
    "                for year in range(min_year, max_year):\n",
    "                    time_constraint.end_dt = time_constraint.end_dt.replace(year=year)\n",
    "                    corrs = TemporalPearson.create_user_corrs(self.cache.movie_ratings, time_constraint,\n",
    "                                                              self.min_common_elements)\n",
    "                    self.cache.user_corrs_in_bulk[year] = corrs\n",
    "            else:\n",
    "                raise Exception(\"Trying to cache user correlations in bulk for max_limit \"\n",
    "                                \"but start time is not max_limit!\")\n",
    "        else:\n",
    "            raise Exception(\"Trying to create bulk corr cache when use_bulk_corr_cache is False\")\n",
    "\n",
    "    def cache_user_corrs_in_bulk_for_time_bins(self, time_constraint: TimeConstraint, min_year, max_year,\n",
    "                                               min_time_bin_size=2, max_time_bin_size=10):\n",
    "        if self.cache.use_bulk_corr_cache:\n",
    "            if time_constraint is not None and time_constraint.is_valid_time_bin():\n",
    "                del self.cache.user_corrs_in_bulk    # invalidate old cache\n",
    "                self.cache.user_corrs_in_bulk = dict()\n",
    "                for time_bin_size in range(min_time_bin_size, max_time_bin_size):\n",
    "                    self.cache.user_corrs_in_bulk[time_bin_size] = dict()\n",
    "                    for shift in range(0, time_bin_size):\n",
    "                        curr_year = min_year + shift\n",
    "                        while (curr_year + time_bin_size) < max_year:\n",
    "                            time_constraint = TimeConstraint(start_dt=datetime(curr_year, 1, 1),\n",
    "                                                             end_dt=datetime(curr_year + time_bin_size, 1, 1))\n",
    "                            corrs = TemporalPearson.create_user_corrs(self.cache.movie_ratings,\n",
    "                                                                      time_constraint,\n",
    "                                                                      self.min_common_elements)\n",
    "                            self.cache.user_corrs_in_bulk[time_bin_size][curr_year] = corrs\n",
    "                            curr_year += time_bin_size\n",
    "        else:\n",
    "            raise Exception(\"Trying to create bulk corr cache when use_bulk_corr_cache is False\")\n",
    "\n",
    "    @property\n",
    "    def time_constraint(self):\n",
    "        return self._time_constraint\n",
    "\n",
    "    @time_constraint.setter\n",
    "    def time_constraint(self, value):\n",
    "        self._time_constraint = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainsetUser:\n",
    "    \"\"\"\n",
    "    TrainsetUser provides user related dataset utility methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, cache: Cache):\n",
    "        \"\"\"\n",
    "        :param cache: Input cache must have movie_ratings not None !\n",
    "        \"\"\"\n",
    "        self.cache = cache\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "    def get_users(self):\n",
    "        \"\"\"\n",
    "        Get list of unique 'user_id's\n",
    "\n",
    "        Since MovieLens Have 'user_id's from 0 to 610 without any missing user, for now sending that directly\n",
    "        Uncomment the other lines later\n",
    "\n",
    "        :return: the ids of the users found in movie_ratings\n",
    "        \"\"\"\n",
    "        #\n",
    "        # if self.cache.is_ratings_cached:\n",
    "        #     data = self.cache.ratings\n",
    "        # else:\n",
    "        #     data = self.cache.movie_ratings\n",
    "        #\n",
    "        # return pd.unique(data['user_id'])\n",
    "        return range(0, 611)\n",
    "\n",
    "    def get_active_users(self, n=10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get Users in sorted order where the first one is the one who has given most ratings.\n",
    "\n",
    "        :param n: Number of users to retrieve.\n",
    "        :return: user DataFrame with index of 'user_id' and columns of ['mean_rating', 'No_of_ratings'] .\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:                         # 30% faster than other choice\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        active_users = pd.DataFrame(data.groupby('user_id')['rating'].mean())\n",
    "        active_users['No_of_ratings'] = pd.DataFrame(data.groupby('user_id')['rating'].count())\n",
    "        active_users.sort_values(by=['No_of_ratings'], ascending=False, inplace=True)\n",
    "        active_users.columns = ['mean_rating', 'No_of_ratings']\n",
    "        return active_users.head(n)\n",
    "\n",
    "    def get_random_users(self, n=1):\n",
    "        \"\"\"\n",
    "        Get list of random n number of 'user_id's\n",
    "\n",
    "        :param n: Number of random users\n",
    "        :return: List of random 'user_id's\n",
    "        \"\"\"\n",
    "\n",
    "        return random.choices(population=self.get_users(), k=n)\n",
    "\n",
    "    def get_user_ratings(self, user_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the ratings given by of the chosen users\n",
    "\n",
    "        :param user_id: id of the chosen user\n",
    "        :return: Ratings given by the 'user_id'\n",
    "        \"\"\"\n",
    "        if self.cache.is_ratings_cached:                         # 2.2x faster than other choice\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        return data.loc[data['user_id'] == user_id]\n",
    "\n",
    "    def get_user_avg(self, user_id: int):\n",
    "\n",
    "        if self.cache.use_avg_ratings_cache:\n",
    "            avg_user_rating = self.cache.avg_user_ratings.loc[user_id]\n",
    "            return avg_user_rating[0] if not avg_user_rating.empty else 0\n",
    "\n",
    "        user_ratings = self.get_user_ratings(user_id=user_id)\n",
    "        return user_ratings.rating.mean() if not user_ratings.empty else 0\n",
    "\n",
    "    def get_timestamp(self, user_id: int, movie_id: int):\n",
    "        \"\"\"\n",
    "        Get the timestamp of the given rating\n",
    "\n",
    "        :param user_id: the users whose rating timestamp we are searching\n",
    "        :param movie_id: id of the movie that the user gave the rating\n",
    "        :return: if found the datetime object otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        timestamp = data.loc[(data['user_id'] == user_id) & (data['item_id'] == movie_id)]\n",
    "        return timestamp.values[0, 3] if not timestamp.empty else None\n",
    "\n",
    "    def get_first_timestamp(self):\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "        return data['timestamp'].min()\n",
    "\n",
    "    def get_user_avg_timestamp(self, user_id: int):\n",
    "        user_ratings = self.get_user_ratings(user_id=user_id)\n",
    "        return user_ratings.timestamp.mean() if not user_ratings.empty else 0\n",
    "\n",
    "    # TODO: Later, create TemporalDatasetUser, and put this method into that one\n",
    "    def get_user_ratings_at(self, user_id: int, at: datetime) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get user ratings up until the given datetime\n",
    "        :param user_id: id of the chosen user\n",
    "        :param at: only those ratings that are before this date will be taken into account\n",
    "        :return: Ratings given by the 'user_id' before given datetime\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        return data.loc[(data['user_id'] == user_id) & (data.timestamp < at)]\n",
    "\n",
    "    # TODO: Later, create TemporalDatasetUser, and put this method into that one\n",
    "    def get_user_avg_at(self, user_id: int, at: datetime):\n",
    "        user_ratings = self.get_user_ratings_at(user_id, at)\n",
    "        return user_ratings.rating.mean() if not user_ratings.empty else 0\n",
    "\n",
    "\n",
    "class TrainsetMovie:\n",
    "    \"\"\"\n",
    "    TrainsetMovie provides movie related dataset utility methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, cache: Cache):\n",
    "        \"\"\"\n",
    "        :param cache: Input cache must have movie_ratings not None !\n",
    "        \"\"\"\n",
    "        self.cache = cache\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "    def get_movie(self, movie_id) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get Movie Record\n",
    "\n",
    "        :return: DataFrame which contains the given 'movie_id's details. If not found empty DataFrame .\n",
    "        \"\"\"\n",
    "        if self.cache.is_movies_cached:\n",
    "            return self.cache.movies.loc[self.cache.movies['item_id'] == movie_id]\n",
    "        return self.cache.movie_ratings.loc[self.cache.movie_ratings['item_id'] == movie_id]\n",
    "\n",
    "    def get_movies(self):\n",
    "        \"\"\"\n",
    "        Get list of unique 'item_id's or in other words the movies.\n",
    "\n",
    "        :return: List of movie ids\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_movies_cached:\n",
    "            return self.cache.movies['item_id'].values.tolist()\n",
    "\n",
    "        return pd.unique(self.cache.movie_ratings['item_id'])\n",
    "\n",
    "    def get_random_movies(self, n=10):\n",
    "        \"\"\"\n",
    "        Get list of random n number of 'item_id's or in other words the movies\n",
    "\n",
    "        :param n: Number of random movies\n",
    "        :return: List of random 'movie_id's\n",
    "        \"\"\"\n",
    "        return random.choices(population=self.get_movies(), k=n)\n",
    "\n",
    "    def get_movies_watched(self, user_id: int, time_constraint: TimeConstraint = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the movies watched by the chosen user.\n",
    "\n",
    "        :param user_id: the user that we want to get the movies he-she has watched.\n",
    "        :param time_constraint: type of the time constraint.\n",
    "        :return: DataFrame of all movies watched with 'item_id', 'rating' columns\n",
    "        \"\"\"\n",
    "\n",
    "        movie_ratings = self.cache.movie_ratings\n",
    "\n",
    "        if time_constraint is None:\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)][['item_id', 'rating']]\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating']]\n",
    "        elif time_constraint.is_valid_time_bin():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating']]\n",
    "        raise Exception(\"Undefined time_constraint is given!\")\n",
    "\n",
    "    def get_movie_rating(self, movie_id: int, user_id: int) -> int:\n",
    "        \"\"\"\n",
    "        Get the movie rating taken by the chosen user\n",
    "\n",
    "        :param movie_id: the movie chosen movie's id\n",
    "        :param user_id: id of the chosen user\n",
    "        :return: Rating given by user. If not found, returns 0\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        movie_rating = data.loc[(data['user_id'] == user_id) & (data['item_id'] == movie_id)]\n",
    "        return movie_rating.values[0, 2] if not movie_rating.empty else 0\n",
    "\n",
    "    def get_random_movie_watched(self, user_id: int) -> int:\n",
    "        \"\"\"\n",
    "        Get random movie id watched.\n",
    "\n",
    "        :param user_id: User of interest\n",
    "        :return:  movie_id or item_id of the random movie watched by the user.\n",
    "                  In case non-valid user_id supplied then returns 0\n",
    "        \"\"\"\n",
    "        movies_watched = self.get_movies_watched(user_id=user_id)\n",
    "        return random.choice(movies_watched['item_id'].values.tolist()) if not movies_watched.empty else 0\n",
    "\n",
    "    def get_random_movies_watched(self, user_id: int, n=2) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get random n movies watched by the user. Only use when n > 2\n",
    "\n",
    "        Use get_random_movie_watched if n=1 since that one 2 fold faster.\n",
    "\n",
    "        :param user_id: the user of interest\n",
    "        :param n: number of random movies to get\n",
    "        :return: DataFrame of movies, if none found then empty DataFrame\n",
    "        \"\"\"\n",
    "        movies_watched = self.get_movies_watched(user_id=user_id)\n",
    "        return random.choices(population=movies_watched['item_id'].values.tolist(),\n",
    "                              k=n) if not movies_watched.empty else movies_watched\n",
    "\n",
    "    def get_random_movie_per_user(self, user_id_list):\n",
    "        \"\"\"\n",
    "        Get random movie for each user given in the 'user_id_list'\n",
    "\n",
    "        :param user_id_list: List of valid user_ids\n",
    "        :return: List of (user_id, movie_id) tuples\n",
    "                where each movie_id is randomly chosen from watched movies of the user_id .\n",
    "                In case any one of the user_id's supplies invalid, then the movie_id will be 0 for that user.\n",
    "        \"\"\"\n",
    "        user_movie_list = list()\n",
    "        for user_id in user_id_list:\n",
    "            user_movie_list.append((user_id, self.get_random_movie_watched(user_id=user_id)))\n",
    "        return user_movie_list\n",
    "\n",
    "\n",
    "class Trainset:\n",
    "    \"\"\"\n",
    "    Trainset class is used to find K nearest neighbours and and predict movies using TemporalPearson class.\n",
    "    \"\"\"\n",
    "    def __init__(self, cache: TemporalCache, min_common_elements: int = 5):\n",
    "        self.cache = cache\n",
    "        self.min_common_elements = min_common_elements\n",
    "        self.similarity = TemporalPearson(time_constraint=None, cache=self.cache)\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "        self.trainset_movie = TrainsetMovie(cache=cache)\n",
    "        self.trainset_user = TrainsetUser(cache=cache)\n",
    "\n",
    "        # if caching is allowed, create user correlations cache\n",
    "        self.similarity.get_corr_matrix()\n",
    "\n",
    "    def predict_movies_watched(self, user_id, n=10, k=10, time_constraint=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_id: user of interest\n",
    "        :param n: Number of movies to predict\n",
    "        :param k: k neighbours to take into account\n",
    "        :param time_constraint: When calculating k neighbours,\n",
    "                                only those that comply to time_constraints will be taken into account.\n",
    "        :return: DataFrame of Predictions where columns = ['prediction', 'rating'] index = 'movie_id'\n",
    "        \"\"\"\n",
    "        # Get all movies watched by a user\n",
    "        movies_watched = self.trainset_movie.get_movies_watched(user_id=user_id)\n",
    "\n",
    "        if movies_watched.empty:\n",
    "            return None\n",
    "\n",
    "        predictions = list()\n",
    "        number_of_predictions = 0\n",
    "        for row in movies_watched.itertuples(index=False):\n",
    "            prediction = self.predict_movie(user_id=user_id, movie_id=row[0],\n",
    "                                            time_constraint=time_constraint, k=k)\n",
    "            if number_of_predictions == n:\n",
    "                break\n",
    "            predictions.append([prediction, row[1], row[0]])\n",
    "            number_of_predictions += 1\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions, columns=['prediction', 'rating', 'movie_id'])\n",
    "        predictions_df.movie_id = predictions_df.movie_id.astype(int)\n",
    "        return predictions_df.set_index('movie_id')\n",
    "\n",
    "    def predict_movie(self, user_id, movie_id, k=10, time_constraint=None, bin_size=-1):\n",
    "        prediction = self.similarity.mean_centered_pearson(user_id=user_id,\n",
    "                                                           movie_id=movie_id,\n",
    "                                                           k_neighbours=\n",
    "                                                           self.get_k_neighbours(user_id, k=k,\n",
    "                                                                                 time_constraint=time_constraint,\n",
    "                                                                                 bin_size=bin_size)\n",
    "                                                           )        \n",
    "        return prediction if prediction <= 5 else 5\n",
    "\n",
    "    def get_k_neighbours(self, user_id, k=10, time_constraint: TimeConstraint = None, bin_size=-1):\n",
    "        \"\"\"\n",
    "        :param user_id: the user of interest\n",
    "        :param k: number of neighbours to retrieve\n",
    "        :param time_constraint: time constraint when choosing neighbours\n",
    "        :param bin_size: Used when using time_bins, in order to select bin from cache\n",
    "        :return: Returns the k neighbours and correlations in between them. If no neighbours found, returns None\n",
    "                 DataFrame which has 'Correlation' column and 'user_id' index.\n",
    "        \"\"\"\n",
    "        self.similarity.time_constraint = time_constraint\n",
    "        user_corr_matrix = self.similarity.get_corr_matrix(bin_size=bin_size)\n",
    "\n",
    "        # Exit if matrix is None, no user found in self.cache.movie_ratings, something is wrong\n",
    "        if user_corr_matrix is None:\n",
    "            return None\n",
    "\n",
    "        # Get the chosen 'user_id's correlations\n",
    "        user_correlations = user_corr_matrix.get(user_id)\n",
    "        if user_correlations is None:\n",
    "            return None\n",
    "\n",
    "        # Drop any null, if found\n",
    "        user_correlations.dropna(inplace=True)\n",
    "        # Create A DataFrame from not-null correlations of the 'user_id'\n",
    "        users_alike = pd.DataFrame(user_correlations)\n",
    "        # Rename the only column to 'correlation'\n",
    "        users_alike.columns = ['correlation']\n",
    "\n",
    "        # Sort the user correlations in descending order\n",
    "        #     so that first one is the most similar, last one least similar\n",
    "        users_alike.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "\n",
    "        # Eliminate Correlation to itself by deleting first row,\n",
    "        #     since biggest corr is with itself it is in first row\n",
    "        return users_alike.iloc[1:k+1] if k is not None else users_alike.iloc[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \"\"\"\n",
    "    Evaluator class is used to test our global timebin architecture and create anaylsis whether it works or not.\n",
    "    As a tip, it didnt worked out well.d But this analysis further guided us towards personal timebin architecture which worked well.\n",
    "    \"\"\"\n",
    "    def __init__(self, trainset: Trainset):\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def evaluate_best_max_year_in_bulk(self, n,\n",
    "                                       n_users, n_movies, k=10,\n",
    "                                       min_year=-1,\n",
    "                                       max_year=-1) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate and collect data about best max year constraint which can be put instead of no constraint.\n",
    "\n",
    "        This method calls 'evaluate_best_max_year_constraint' method 'n' times.\n",
    "        Takes required precautions for bulk calling.\n",
    "\n",
    "        :param n: Number of runs that we run the evaluate_best_max_year_constraint() method\n",
    "        :param n_users: Number of users to check\n",
    "        :param n_movies: Number of movies per user to check\n",
    "        :param k: Number of neighbours of each user to take into account when making prediction\n",
    "        :param min_year: First year to evaluate\n",
    "        :param max_year: Last year to evaluate\n",
    "        :return: (no_constrain_rmse_data, best_year_constraint_results)\n",
    "        \"\"\"\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        time_constraint = TimeConstraint(end_dt=datetime(year=min_year, month=1, day=1))\n",
    "        # Create cache if bulk_corr_cache is allowed\n",
    "        self.trainset.similarity.cache_user_corrs_in_bulk_for_max_limit(time_constraint,\n",
    "                                                                        min_year=min_year,\n",
    "                                                                        max_year=max_year)\n",
    "        \n",
    "        run_results = dict()\n",
    "        for i in range(n):\n",
    "            run_results[i] = self.evaluate_best_max_year_constraint(n_users=n_users, n_movies=n_movies, k=k,\n",
    "                                                                    min_year=min_year, max_year=max_year,\n",
    "                                                                    create_cache=False,)\n",
    "\n",
    "        return run_results\n",
    "\n",
    "    def evaluate_best_max_year_constraint(self, n_users, n_movies, k,\n",
    "                                          max_diff=0.1,\n",
    "                                          min_year=-1, max_year=-1,\n",
    "                                          create_cache=True) -> defaultdict:\n",
    "        \"\"\"\n",
    "        Evaluate the max_year constraint for evaluate_max_year_constraint method.\n",
    "\n",
    "        :param max_diff: maximum difference between rmse when no constraint and with given year constraint.\n",
    "        :param n_users: Number of users to evaluate\n",
    "        :param n_movies: Number of movies per user to evaluate\n",
    "        :param k: Number of neighbours of each user to take into account when making prediction\n",
    "        :param min_year: First year to evaluate\n",
    "        :param max_year: Last year to evaluate\n",
    "        :param create_cache: create cache before running. For bulk callers.\n",
    "        :return: Votes for years where each year got its vote\n",
    "                 when rmse is less than 'max_diff' in between no constraint and year constraint\n",
    "        \"\"\"\n",
    "\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        if n_users > 600:\n",
    "            user_list = self.trainset.trainset_user.get_users()  # No need to random selection, get all users\n",
    "        else:\n",
    "            user_list = self.trainset.trainset_user.get_random_users(n=n_users)  # Select random n users\n",
    "\n",
    "        # Calculate RMSE With No Constraint\n",
    "        no_constraint_data = dict()\n",
    "        for user_id in user_list:\n",
    "            rmse = Accuracy.rmse(self.trainset.predict_movies_watched(user_id, n_movies, k))\n",
    "            no_constraint_data[user_id] = rmse\n",
    "\n",
    "        # # Calculate RMSE With Time Constraint\n",
    "\n",
    "        # Cache all years before processing\n",
    "        time_constraint = TimeConstraint(end_dt=datetime(year=min_year, month=1, day=1))\n",
    "        # Create cache if bulk_corr_cache is allowed\n",
    "        if create_cache:\n",
    "            self.trainset.similarity.cache_user_corrs_in_bulk_for_max_limit(time_constraint,\n",
    "                                                                            min_year=min_year,\n",
    "                                                                            max_year=max_year)\n",
    "        # Votes to years is stored inside time_constraint_data\n",
    "        time_constraint_data = defaultdict(int)\n",
    "        for year in range(min_year, max_year):\n",
    "            time_constraint.end_dt = time_constraint.end_dt.replace(year=year)\n",
    "\n",
    "            for user_id in user_list:\n",
    "                rmse = Accuracy.rmse(self.trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k,\n",
    "                                                                          time_constraint=time_constraint))\n",
    "                if abs(rmse - no_constraint_data[user_id]) < max_diff:\n",
    "                    time_constraint_data[year] += 1\n",
    "\n",
    "        return time_constraint_data\n",
    "\n",
    "    def evaluate_max_year_constraint(self, n_users, n_movies, k, time_constraint):\n",
    "        \"\"\"\n",
    "        Compare given time_constraint with normal where no constraint exists.\n",
    "\n",
    "        Time constraint is of type max_year which means the system will be set to a certain year.\n",
    "\n",
    "        :param n_users: Number of users to evaluate\n",
    "        :param n_movies: Number of movies per user to evaluate\n",
    "        :param k: Number of neighbours to take into account when making movie prediction\n",
    "        :param time_constraint: Time constraint which will be applied.\n",
    "        :return: DataFrame of results which contains rmse with constraint and no constraint, as well as runtime.\n",
    "        \"\"\"\n",
    "        trainset = self.trainset\n",
    "        data = list()\n",
    "\n",
    "        for i in range(n_users):\n",
    "            # Get Random User\n",
    "            user_id = random.randint(1, 610)\n",
    "            # Predict movies for user and record runtime\n",
    "            st = default_timer()\n",
    "            rmse = Accuracy.rmse(\n",
    "                trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k, time_constraint=None))\n",
    "            r1 = default_timer() - st\n",
    "            # Predict movies with time_constraint for user and record runtime\n",
    "            st = default_timer()\n",
    "            time_constrained_rmse = Accuracy.rmse(\n",
    "                trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k, time_constraint=time_constraint))\n",
    "            r2 = default_timer() - st\n",
    "            # Save iteration data\n",
    "            data.append([user_id, rmse, r1, time_constrained_rmse, r2])\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        data.columns = ['user_id', 'rmse', 'runtime1', 'temporal_rmse', 'runtime2']\n",
    "        data.set_index('user_id', inplace=True)\n",
    "        return data\n",
    "\n",
    "    def evaluate_time_bins_in_bulk(self, n, n_users, k=10,\n",
    "                                   min_year=-1,\n",
    "                                   max_year=-1,\n",
    "                                   min_time_bin_size=2, max_time_bin_size=10):\n",
    "        \"\"\"\n",
    "        Evaluate time bins and return the results.\n",
    "\n",
    "        This method calls 'evaluate_time_bins' method 'n' times. Takes required precautions for bulk calling.\n",
    "\n",
    "        :param n: Number of runs\n",
    "        :param n_users: Number of users\n",
    "        :param k: Number of neighbours will be used when making prediction\n",
    "        :param min_year: First year to start when taking time bins\n",
    "        :param max_year: When to stop when taking time bins, last is not included.\n",
    "        :param min_time_bin_size: Minimum bin size in years\n",
    "        :param max_time_bin_size: Maximum bin size in years\n",
    "        :return: Evaluation results\n",
    "        \"\"\"\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        # Cache all years before processing\n",
    "        time_constraint = TimeConstraint(start_dt=datetime(year=min_year, month=1, day=1),\n",
    "                                         end_dt=datetime(year=max_year, month=1, day=1))\n",
    "        self.trainset.similarity.cache_user_corrs_in_bulk_for_time_bins(time_constraint,\n",
    "                                                                        min_year=min_year,\n",
    "                                                                        max_year=max_year,\n",
    "                                                                        min_time_bin_size=min_time_bin_size,\n",
    "                                                                        max_time_bin_size=max_time_bin_size)\n",
    "\n",
    "        run_results = dict()\n",
    "        for i in range(n):\n",
    "            run_results[i] = self.evaluate_time_bins(n_users=n_users, k=k, min_year=min_year, max_year=max_year,\n",
    "                                                     min_time_bin_size=min_time_bin_size,\n",
    "                                                     max_time_bin_size=max_time_bin_size,\n",
    "                                                     create_cache=False)\n",
    "\n",
    "        return run_results\n",
    "\n",
    "    def evaluate_time_bins(self, n_users, k, min_year=-1, max_year=-1,\n",
    "                           min_time_bin_size=2, max_time_bin_size=10,\n",
    "                           create_cache=True) -> dict:\n",
    "        \"\"\"\n",
    "\n",
    "        :param n_users: Number of users\n",
    "        :param k: Number of neighbours will be used when making prediction\n",
    "        :param min_year: First year to start when taking time bins\n",
    "        :param max_year: When to stop when taking time bins, last is not included.\n",
    "        :param min_time_bin_size: Minimum bin size in years\n",
    "        :param max_time_bin_size: Maximum bin size in years\n",
    "        :param create_cache: Create cache before calling time bins. For bulk callers.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        trainset = self.trainset\n",
    "\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        if n_users > 600:\n",
    "            user_list = trainset.trainset_user.get_users()\n",
    "        else:\n",
    "            user_list = trainset.trainset_user.get_random_users(n=n_users)\n",
    "        user_movie_list = trainset.trainset_movie.get_random_movie_per_user(user_list)\n",
    "        data = dict()\n",
    "\n",
    "        result = list()\n",
    "\n",
    "        if create_cache:\n",
    "            # Cache all years before processing\n",
    "            time_constraint = TimeConstraint(start_dt=datetime(year=min_year, month=1, day=1),\n",
    "                                             end_dt=datetime(year=max_year, month=1, day=1))\n",
    "            self.trainset.similarity.cache_user_corrs_in_bulk_for_time_bins(time_constraint,\n",
    "                                                                            min_year=min_year,\n",
    "                                                                            max_year=max_year,\n",
    "                                                                            min_time_bin_size=min_time_bin_size,\n",
    "                                                                            max_time_bin_size=max_time_bin_size)\n",
    "\n",
    "        # Take each bins where first bin 'min_time_bin_size' years, last one 'max_time_bin_size - 1' years\n",
    "        for time_bin_size in range(min_time_bin_size, max_time_bin_size):\n",
    "            # Shift each time_bin starting with 0 years up until (time_bin-1) years\n",
    "            for shift in range(0, time_bin_size):\n",
    "                curr_year = min_year + shift\n",
    "                predictions = list()\n",
    "                start_time = default_timer()\n",
    "                # Scan and make predictions for all the time_bins\n",
    "                while (curr_year + time_bin_size) < max_year:\n",
    "                    for user_id, movie_id in user_movie_list:\n",
    "                        p = trainset.predict_movie(user_id=user_id, movie_id=movie_id, k=k,\n",
    "                                                   time_constraint=TimeConstraint(start_dt=datetime(curr_year, 1, 1),\n",
    "                                                                                  end_dt=datetime(curr_year+time_bin_size, 1, 1)),\n",
    "                                                   bin_size=time_bin_size)\n",
    "                        # if prediction has been done successfully\n",
    "                        if p != 0:\n",
    "                            r = trainset.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "                            # Append (prediction, actual_rating)\n",
    "                            predictions.append((p, r))\n",
    "                    curr_year += time_bin_size\n",
    "                runtime = default_timer() - start_time\n",
    "                bin_rmse = Accuracy.rmse(predictions=predictions)\n",
    "                iteration_results = {\"bin_size\": time_bin_size,\n",
    "                                     \"start_year\": min_year + shift,\n",
    "                                     \"predictions\": predictions,\n",
    "                                     \"rmse\": bin_rmse,\n",
    "                                     \"runtime\": runtime\n",
    "                                     }\n",
    "                result.append(iteration_results)\n",
    "\n",
    "        data['result'] = result\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = TemporalCache(time_constraint=None, \n",
    "                  is_ratings_cached=True,\n",
    "                  is_movies_cached=True,\n",
    "                  is_movie_ratings_cached=True,\n",
    "                  ratings=MovieLensDataset.load_ratings(r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv'),\n",
    "                  movies=MovieLensDataset.load_movies(r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv'),\n",
    "                  movie_ratings=MovieLensDataset.load(),\n",
    "                  is_user_correlations_cached=True,\n",
    "                  use_bulk_corr_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainset(cache=c, min_common_elements=5)\n",
    "e = Evaluator(trainset=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timebin Based Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TimebinSimilarity:\n",
    "    \"\"\"\n",
    "    TembinSimilarity is a way to provide personalized timebin based recommendations.\n",
    "    Here we define an alternative to classical pearson by providing temporal aspect.\n",
    "    Here is what we do in summary:\n",
    "      1. Choose a person to make prediction on (as always).\n",
    "      2. Take the last s movie ratings of this person as a timebin from a random timepoint.(user must have at least s movie watched before!)\n",
    "      3. Find neighbour timebins to the selected timebin.(using correlations between them, higher, better)\n",
    "      4. Predict rating for user using the timebin neighbours the same way as we use in k nearest neighbour.\n",
    "    \"\"\"\n",
    "    def __init__(self, ratings, trainset, k=5, r=3, s=10, p=3, corr_threshold=0.5, \n",
    "                 neighbour_min_s=5, neighbour_max_s=50, neighbour_step_size=5):\n",
    "        \"\"\"\n",
    "        :param k: Minimum number of ratings in common in between neighbour users when taking timebins of them. \n",
    "        :param r: Minimum number of ratings in common between neighbour timebins.\n",
    "        :param s: Maximum number of movies to include inside of the timebin.\n",
    "        :param p: Minimum number of neighbour timebins when making prediction.\n",
    "        :param neighbour_min_s: Minimum number of movies to include inside neighbour timebins\n",
    "        :param neighbour_max_s: Maximum number of movies to include inside neighbour timebins\n",
    "        :param neighbour_step_size: Number of movies to extend per step the timebin size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.ratings.sort_values(['user_id', 'timestamp'], ignore_index=True, inplace=True)\n",
    "        self.trainset = trainset\n",
    "        self.k = k\n",
    "        self.r = r\n",
    "        self.s = s\n",
    "        self.p = p\n",
    "        self.corr_threshold = corr_threshold\n",
    "        \n",
    "        self.neighbour_min_s = neighbour_min_s\n",
    "        self.neighbour_max_s = neighbour_max_s\n",
    "        self.neighbour_step_size = neighbour_step_size\n",
    "        \n",
    "        if s < 1:\n",
    "            raise Exception(\"Timebin size must be positive.\")\n",
    "        \n",
    "        # For ease of use, save these\n",
    "        self.trainset_user = trainset.trainset_user\n",
    "        self.trainset_movie = trainset.trainset_movie\n",
    "        self.first_timestamp = ratings['timestamp'].min()\n",
    "                \n",
    "        # Set these before calculating any correlations\n",
    "        self.user_id = None\n",
    "        self.timebin = None\n",
    "        self.timebin_user_avg_rating = None\n",
    "       \n",
    "    def find_timebin_corr(self, merged:pd.DataFrame, neighbour_avg_rating):\n",
    "        \"\"\"\n",
    "        Find the correlation between the given neighbour timebin and the self.timebin\n",
    "        \n",
    "        :param merged: Merged version of neighbour timebin and self.timebin\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate Pearson Correlation in between the self.timebin and given neighbour\n",
    "        numenator = ((merged['rating_x'] - self.timebin_user_avg_rating) * (merged['rating_y'] - neighbour_avg_rating)).sum()\n",
    "        denominator = math.sqrt(((merged['rating_x'] - self.timebin_user_avg_rating) ** 2).sum())\n",
    "        denominator *= math.sqrt(((merged['rating_y'] - neighbour_avg_rating) ** 2).sum())\n",
    "        pearson = numenator / denominator\n",
    "        \n",
    "        return pearson\n",
    "        \n",
    "    \n",
    "    def get_movies_watched(self, user_id: int, time_constraint: TimeConstraint = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the movies watched by the chosen user.\n",
    "\n",
    "        :param user_id: the user that we want to get the movies he-she has watched.\n",
    "        :param time_constraint: type of the time constraint.\n",
    "        :return: DataFrame of all movies watched with 'item_id', 'rating' columns\n",
    "        \"\"\"\n",
    "\n",
    "        movie_ratings = self.ratings\n",
    "\n",
    "        if time_constraint is None:\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "        elif time_constraint.is_valid_time_bin():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "        return None   # Means the Time_constraint is not a valid timebin!\n",
    "    \n",
    "    def get_timebin2(self, user_id, timebin_i, timebin_size):\n",
    "        \"\"\"\n",
    "        Generate the timebin by using given info.\n",
    "        timebin_i is the index the first movie\n",
    "        timebin_size is the number of movies to take starting at timebin_i th index.\n",
    "        \"\"\"\n",
    "        all_movies_watched = self.get_movies_watched(user_id)\n",
    "        return all_movies_watched.iloc[timebin_i:timebin_i+timebin_size]\n",
    "    \n",
    "    def get_timebin3(self, user_id, timebin_i, timebin_size, i):\n",
    "        \"\"\"\n",
    "        Remove the i th rating from the timebin while regenerating the timebin.\n",
    "        \"\"\"\n",
    "        all_movies_watched = self.get_movies_watched(user_id)\n",
    "        original_timebin = all_movies_watched.iloc[timebin_i:timebin_i+timebin_size] \n",
    "        return pd.concat([original_timebin.iloc[0:i], original_timebin.iloc[i+1:]]) \n",
    "    \n",
    "    def get_timebin_neighbours(self, user_id:int, timebin_i, timebin_size, i=None):\n",
    "        \"\"\"\n",
    "        Get neighbours who has rated at least p movies in common with the user.\n",
    "        \"\"\"\n",
    "        ratings = self.ratings\n",
    "        \n",
    "        # Create the identified user timebin\n",
    "        if i is not None:\n",
    "            timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "        else:\n",
    "            timebin = self.get_timebin2(user_id, timebin_i, timebin_size)\n",
    "        \n",
    "        # Count number of common ratings with other users\n",
    "        userlist = [0 for i in range(611)]\n",
    "        for movie_id in timebin.index.values.tolist():\n",
    "            users_who_watched = ratings.loc[(ratings['item_id'] == movie_id)][['user_id']].values.tolist()\n",
    "            for user_who_watched in users_who_watched:\n",
    "                userlist[user_who_watched[0]] += 1\n",
    "\n",
    "        # save as neighbour, if common rating count greater than k\n",
    "        neighbour_id_list = []\n",
    "        for i in range(0, 611):\n",
    "            if userlist[i] > self.k:\n",
    "                neighbour_id_list.append(i)\n",
    "        return neighbour_id_list\n",
    "    \n",
    "    \n",
    "    def get_neighbour_timebins(self, neighbour_id:int)->list:\n",
    "        \"\"\"\n",
    "        Given a neighbour, get its list of timebins\n",
    "        \"\"\"\n",
    "        # Start by taking all movies watched by the neighbour\n",
    "        all_movies_watched = self.get_movies_watched(neighbour_id)\n",
    "        n_movies = len(all_movies_watched)\n",
    "        neighbour_timebins = list()\n",
    "        \n",
    "        # For each timebin_size\n",
    "        for timebin_size in range(self.neighbour_min_s, self.neighbour_max_s, self.neighbour_step_size):\n",
    "            # Traverse the all movies by taking 'timebin_size' piece of ratings per loop\n",
    "            for i in range(0, n_movies, timebin_size):\n",
    "                # Insert the timebin, its index i, and its size timebin_size into the list as a tuple\n",
    "                neighbour_timebins.append(  (all_movies_watched.iloc[i:i+timebin_size], i, timebin_size)  )\n",
    "        \n",
    "        return neighbour_timebins\n",
    "    \n",
    "    def get_most_similar_timebins(self, user_id, timebin_i, timebin_size, i = None):\n",
    "        \"\"\"\n",
    "        Get Neighbour Timebins\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create the user timebin\n",
    "        if i is not None:\n",
    "            timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "        else:\n",
    "            timebin = self.get_timebin2(user_id, timebin_i, timebin_size)\n",
    "        \n",
    "        time_constraint = TimeConstraint(end_dt=timebin.iloc[len(timebin)-1]['timestamp'])\n",
    "        # Set the self.timebin as the timebin of interest with required details for correlation calculations\n",
    "        self.timebin = timebin\n",
    "        self.user_id = user_id\n",
    "        self.timebin_user_avg_rating = self.trainset_user.get_user_avg_at(user_id, time_constraint.end_dt)\n",
    "        \n",
    "        # Neighbours contains users who has rated self.k movies in common\n",
    "        neighbours = self.get_timebin_neighbours(user_id, timebin_i, timebin_size, i)\n",
    "        data = list()\n",
    "        \n",
    "        # For Each neighbour\n",
    "        \n",
    "        for neighbour_id in neighbours:\n",
    "            \n",
    "            # neighbour can not be user himself! results in perfect predictions.d :)\n",
    "            if neighbour_id == self.user_id:\n",
    "                continue\n",
    "            \n",
    "            neighbour_timebins = self.get_neighbour_timebins(neighbour_id) \n",
    "            neighbour_avg_rating = self.trainset_user.get_user_avg_at(neighbour_id, time_constraint.end_dt)\n",
    "            \n",
    "            # For each neighbour timebin, calculate pearson between the timebin and neighbour timebin \n",
    "            for neighbour_timebin, timebin_i, timebin_size in neighbour_timebins:\n",
    "                # Filter unrelated movie ratings and only keep common movie ratings\n",
    "                \n",
    "                merged = neighbour_timebin.merge(self.timebin, on='item_id')\n",
    "                common_elements = len(merged)\n",
    "                \n",
    "                # If less than self.r movies in common rated in the neighbour_timebin, dont process this timebin\n",
    "                if common_elements < self.r:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Pearson Correlation between neighbour timebin and self.timebin\n",
    "                corr = self.find_timebin_corr(merged, neighbour_avg_rating)\n",
    "                \n",
    "                # Dont include the neighbour timebin if corr is invalid or less than corr_threshold\n",
    "                if math.isnan(corr) or corr < self.corr_threshold:                     \n",
    "                    continue\n",
    "                \n",
    "                binsize_in_days = TimebinSimilarity.get_timebin_size(\n",
    "                                    TimeConstraint(start_dt=neighbour_timebin.iloc[0]['timestamp'], \n",
    "                                                   end_dt=neighbour_timebin.iloc[len(neighbour_timebin)-1]['timestamp']))\n",
    "                \n",
    "                data.append( (neighbour_id, common_elements, corr, timebin_i, timebin_size, binsize_in_days) )\n",
    "        \n",
    "        return pd.DataFrame(data, columns=['neighbour_id', 'n_common','pearson_corr', 'timebin_i', 'timebin_size', 'timebin_size_in_days'])\n",
    "    \n",
    "    \n",
    "    def get_timebin_neighbours_data(self, timebin, similar_timebins):\n",
    "        \"\"\"\n",
    "        Get timebin possessors' ratings and timebin correlations as the output\n",
    "        \"\"\"\n",
    "        # Store data in order to return as result\n",
    "        data = defaultdict(list)\n",
    "        for row in similar_timebins.itertuples(index=False):\n",
    "            # Get neighbour timebin data\n",
    "            neighbour_id = row[0]\n",
    "            n_common = row[1]\n",
    "            corr = row[2]\n",
    "            timebin_i = row[3]\n",
    "            timebin_size = row[4]\n",
    "            timebin_size_in_days = row[5]\n",
    "            \n",
    "            # Create the neighbour timebin from its data\n",
    "            neighbour_bin = self.get_timebin2(neighbour_id, timebin_i, timebin_size)\n",
    "            \n",
    "            # Get rid of movie ratings of the neighbour that are not found in the timebin\n",
    "            merged_bin = pd.merge(timebin, neighbour_bin, left_index=True, right_index=True)\n",
    "            \n",
    "            # For each common movie rating, store neighbour rating and its correlation to the timebin\n",
    "            for bin_row in merged_bin.itertuples(index=True):\n",
    "                curr_movie = bin_row[0]\n",
    "                neighbour_rating = bin_row[3]\n",
    "                #print(bin_row[0], bin_row[1], bin_row[2], bin_row[3], bin_row[4])\n",
    "                data[curr_movie].append( (neighbour_rating, corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days) )\n",
    "        return data\n",
    "    \n",
    "    def get_timebin_neighbours_data_for_no_bias(self, similar_timebins, movie_id):\n",
    "        \"\"\"\n",
    "            Collect neighbour ratings to the movie with id 'movie_id'.\n",
    "        \"\"\"\n",
    "        \n",
    "        data = list()\n",
    "        for row in similar_timebins.itertuples(index=False):\n",
    "            # Get neighbour timebin data\n",
    "            neighbour_id = row[0]\n",
    "            n_common = row[1]\n",
    "            corr = row[2]\n",
    "            timebin_i = row[3]\n",
    "            timebin_size = row[4]\n",
    "            timebin_size_in_days = row[5]\n",
    "            \n",
    "            # Create the neighbour timebin from its data\n",
    "            neighbour_bin = self.get_timebin2(neighbour_id, timebin_i, timebin_size)\n",
    "            rating = None\n",
    "            try: \n",
    "                rating = neighbour_bin.loc[movie_id]     # test whether the neighbour has rating for the item\n",
    "            except KeyError:\n",
    "                continue                                 # if neighbour dont have rating for the item, then pass this round of loop\n",
    "            \n",
    "            # insert rating for the neighbour into data \n",
    "            #  and also insert other data identifying the neighbour(for in case we use them in analysis)\n",
    "            if rating is not None:\n",
    "                data.append( (rating[0], corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days) )\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def compare_normal_and_timebin_predictions_no_bias(self, n_users):\n",
    "        \"\"\"\n",
    "        Compare n number of users but this time do not include the rating that we are trying to find inside of a timebin.\n",
    "        \"\"\"\n",
    "        # list of ((normal_rmse, timebin_rmse), user_id, timebin_i, timebin_size, data) tuples\n",
    "        output = list()\n",
    "        \n",
    "        # collected data count\n",
    "        count = 0 \n",
    "        \n",
    "        while count < n_users:\n",
    "            \n",
    "            print(\"Predict for a new user\\n\")\n",
    "            \n",
    "            # Choose a random user\n",
    "            user_id = random.randint(0, 610)\n",
    "            \n",
    "            # Choose a random timebin of size self.s\n",
    "            movies_watched = self.get_movies_watched(user_id)\n",
    "            max_movie_index = len(movies_watched) - self.s - 1\n",
    "            if max_movie_index <= 0:\n",
    "                continue\n",
    "            \n",
    "            timebin_i = random.randint(0, max_movie_index)\n",
    "            timebin = self.get_timebin2(user_id, timebin_i, self.s)\n",
    "            timebin_size = len(timebin)\n",
    "            \n",
    "            if timebin is None or len(timebin) < self.r:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction without timebins\n",
    "            \n",
    "            # Predict all the movies inside of the timebin by the classic way, using pearson correlation\n",
    "            normal_predictions = TimebinSimilarity.predict_movies_watched(timebin=timebin, trainset=self.trainset, \n",
    "                                                                          user_id=user_id)\n",
    "            normal_rmse = Accuracy.rmse(normal_predictions)\n",
    "            normal_threshold_accuracy  = Accuracy.threshold_accuracy(normal_predictions)\n",
    "            \n",
    "            # In case we are not able to make predictions without using timebins\n",
    "            # dont make any further processing since we can not compare 0 with timebin rmse \n",
    "            if normal_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction with timebins\n",
    "            predictions = list()\n",
    "            # Here we will be removing each movie from timebin\n",
    "            # then find similar timebin to the new version of the timebin\n",
    "            # use the neighbours and their correlation to make movie prediction on the selected movie\n",
    "            for i in range(timebin_size):   # i stands for the index of the movie found in the timebin\n",
    "                \n",
    "                # Get similar timebins\n",
    "                similar_timebins = self.get_most_similar_timebins(user_id, timebin_i, timebin_size, i)\n",
    "                \n",
    "                if similar_timebins.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Drop duplicate (neighbour_id, n_common, pearson_corr, timebin_i) tuples so that now no repeating timebin exists\n",
    "                similar_timebins.drop_duplicates(['neighbour_id','n_common', 'pearson_corr', 'timebin_i'], inplace=True)\n",
    "                \n",
    "                movie_id = timebin.index[i]\n",
    "                \n",
    "                # First Method\n",
    "#                 data = self.get_timebin_neighbours_data_for_no_bias(similar_timebins, movie_id)\n",
    "#                 prediction = TimebinSimilarity.predict_movie(data, k=10, min_neighbour_count = self.p)\n",
    "                # Second Method\n",
    "                prediction = TimebinSimilarity.predict_movie_with_user_corrs(movie_id=movie_id, \n",
    "                                                                             similar_timebins=similar_timebins, \n",
    "                                                                             trainset_movie=self.trainset_movie, \n",
    "                                                                             k=10, \n",
    "                                                                             min_neighbour_count=self.p)\n",
    "                actual = self.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "                print(movie_id, prediction, actual)\n",
    "                predictions.append( (prediction, actual) )\n",
    "            \n",
    "            timebins_rmse = Accuracy.rmse(predictions)\n",
    "            timebin_threshold_accuracy = Accuracy.threshold_accuracy(predictions)\n",
    "            \n",
    "            # In case timebin_rmse is 0 continue since we can not compare with normal rmse\n",
    "            if timebins_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            # Debug output\n",
    "            print(f\"Normal RMSE: {normal_rmse:.2} Timebin RMSE:{timebins_rmse:.2} \\\n",
    "                    Normal Threshold Acc: {int(normal_threshold_accuracy)}% Timebin Threshold Acc: {int(timebin_threshold_accuracy)}%\")\n",
    "\n",
    "            # Save the data\n",
    "#             output.append( ((normal_rmse, timebins_rmse), \n",
    "#                             (normal_threshold_accuracy, timebin_threshold_accuracy), \n",
    "#                             user_id, timebin_i, timebin_size, \n",
    "#                             data) )\n",
    "            # we saved a data succesfully, increment collected data cout \n",
    "            count += 1\n",
    "            \n",
    "        return output\n",
    "            \n",
    "    \n",
    "    \n",
    "    def compare_normal_and_timebin_predictions(self, n_users):\n",
    "        \"\"\"\n",
    "        Compare n number of users with biased fashion where the prediction we are trying to find is included inside timebin.\n",
    "        \"\"\"\n",
    "        \n",
    "        # list of ((normal_rmse, timebin_rmse),user_id, timebin_i, timebin_size, data) tuples\n",
    "        output = list()\n",
    "        \n",
    "        # collected data count\n",
    "        count = 0\n",
    "        \n",
    "        while count < n_users:\n",
    "            # Choose a random user\n",
    "            user_id = random.randint(0,610)\n",
    "            \n",
    "            ### Choose Random timebin\n",
    "            \n",
    "            # Get all movies that has been watched by the user\n",
    "            movies_watched = self.get_movies_watched(user_id)\n",
    "            \n",
    "            # take a random starting point and take self.s piece movies starting from that point\n",
    "            max_movie_index = len(movies_watched)-self.s-1\n",
    "            if max_movie_index <= 0:\n",
    "                continue\n",
    "            timebin_i = random.randint(0, max_movie_index)\n",
    "            timebin = self.get_timebin2(user_id, timebin_i, self.s)\n",
    "            timebin_size = len(timebin)\n",
    "            \n",
    "            if timebin is None or len(timebin) < self.r:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction without timebins\n",
    "            \n",
    "            # Predict all the movies inside of the timebin by the classic way,using pearson correlation\n",
    "            normal_predictions = TimebinSimilarity.predict_movies_watched(timebin=timebin, trainset = self.trainset, \n",
    "                                                                                 user_id=user_id)\n",
    "            normal_rmse = Accuracy.rmse(normal_predictions)\n",
    "            normal_threshold_accuracy  = Accuracy.threshold_accuracy(normal_predictions)\n",
    "            \n",
    "            # In case we are not able to make predictions without using timebins\n",
    "            # dont make any further processing since we can not compare 0 with timebin rmse \n",
    "            if normal_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction with timebins\n",
    "            # Get similart timebins\n",
    "            \n",
    "            similar_timebins = self.get_most_similar_timebins(user_id, timebin_i, timebin_size)\n",
    "            \n",
    "            # Drop duplicate (neighbour_id, n_common, pearson_corr, timebin_i) tuples so that now no repeating timebin exists\n",
    "            similar_timebins.drop_duplicates(['neighbour_id','n_common', 'pearson_corr', 'timebin_i'], inplace=True)\n",
    "            # Sort the timebins for the purpose of debugging\n",
    "            #similar_timebins.sort_values('pearson_corr', ascending=False, inplace=True, ignore_index=True)\n",
    "            \n",
    "            data = self.get_timebin_neighbours_data(timebin, similar_timebins)\n",
    "                \n",
    "            predictions = TimebinSimilarity.predict_movies_watched_using_timebin_neighbours(data, \n",
    "                                                                                            self.trainset_movie, \n",
    "                                                                                            user_id, \n",
    "                                                                                            min_neighbour_count=self.p)\n",
    "\n",
    "            timebins_rmse = Accuracy.rmse(predictions)\n",
    "            timebin_threshold_accuracy = Accuracy.threshold_accuracy(predictions)\n",
    "            \n",
    "            # In case timebin_rmse is 0 continue since we can not compare with normal rmse\n",
    "            if timebins_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            # Debug output\n",
    "            print(f\"Normal RMSE: {normal_rmse:.2} Timebin RMSE:{timebins_rmse:.2} \\\n",
    "                    Normal Threshold Acc: {int(normal_threshold_accuracy)}% Timebin Threshold Acc: {int(timebin_threshold_accuracy)}%\")\n",
    "\n",
    "            # Save the data\n",
    "            output.append( ((normal_rmse, timebins_rmse), \n",
    "                            (normal_threshold_accuracy, timebin_threshold_accuracy), \n",
    "                            user_id, timebin_i, timebin_size, \n",
    "                            data) )\n",
    "\n",
    "            # we saved a data succesfully, increment collected data cout \n",
    "            count += 1\n",
    "            \n",
    "        return output\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def predict_movie_with_user_corrs(movie_id, similar_timebins, trainset_movie, k=10, min_neighbour_count=5):\n",
    "        neighbours_data = similar_timebins[['neighbour_id', 'pearson_corr']].groupby('neighbour_id').mean()\n",
    "        neighbours_data.sort_values(by='pearson_corr', ascending=False, inplace=True)\n",
    "        \n",
    "        weighted_sum = 0\n",
    "        weight_sum = 0\n",
    "        count = 0\n",
    "        for index, row in similar_timebins[['neighbour_id', 'pearson_corr']].groupby('neighbour_id').mean().iterrows():\n",
    "            neighbour_id = index\n",
    "            corr = row[0]\n",
    "            rating = trainset_movie.get_movie_rating(neighbour_id, movie_id)\n",
    "            weighted_sum += rating * corr\n",
    "            weight_sum += corr\n",
    "            # Only take k nearest neighbours\n",
    "            if count == k:\n",
    "                break\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "        if count < min_neighbour_count:\n",
    "            return 0\n",
    "        \n",
    "        prediction = weighted_sum / weight_sum\n",
    "        \n",
    "        return prediction \n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movie(data, k=10,  min_neighbour_count=5):\n",
    "        \"\"\"\n",
    "        Make prediction by using the neighbour timebin data on the movie of interest.\n",
    "        K nearest neighbours is used only.\n",
    "        \"\"\"\n",
    "        # Sort the data by corr\n",
    "        data.sort(key=lambda data_element: data_element[1])\n",
    "        # each row of data ->(rating, corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days)\n",
    "        weighted_sum = 0\n",
    "        weight_sum = 0\n",
    "        count = 0\n",
    "        for (rating, corr, _, _, _, _, _) in data:\n",
    "            weighted_sum += rating * corr\n",
    "            weight_sum += corr\n",
    "            \n",
    "            # Only take k neighbours\n",
    "            if count == k:\n",
    "                break\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "        if count < min_neighbour_count:\n",
    "            return 0\n",
    "        \n",
    "        prediction = weighted_sum / weight_sum\n",
    "        \n",
    "        return prediction \n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movies_watched_using_timebin_neighbours(data, trainset_movie, user_id, min_neighbour_count=5):\n",
    "        predictions = list()\n",
    "        \n",
    "        # For each movie and neighbour data found for that movie\n",
    "        for movie_id, rating_corr_list in data.items():\n",
    "            # by using the neighbours correlations, make prediction\n",
    "            weighted_sum = 0\n",
    "            weight_sum = 0\n",
    "            count = 0\n",
    "            for rating_corr in rating_corr_list:\n",
    "                count += 1\n",
    "                rating = rating_corr[0]\n",
    "                corr = rating_corr[1]\n",
    "                weighted_sum += rating * corr\n",
    "                weight_sum += corr\n",
    "            if count < min_neighbour_count:         # if less than min_neighbour_count neighbour found, pass\n",
    "                continue\n",
    "            prediction = weighted_sum / weight_sum\n",
    "            actual = trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "            predictions.append( (prediction, actual) )\n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movies_watched_using_timebin_neighbours2(data, trainset_movie, user_id, min_neighbour_count=5):\n",
    "        predictions = list()\n",
    "        \n",
    "        for movie_id, rating_corr_list in data.items():\n",
    "            weighted_sum = 0\n",
    "            weight_sum = 0\n",
    "            count = 0\n",
    "            for rating_corr in rating_corr_list:\n",
    "                count += 1\n",
    "                rating = rating_corr[0]\n",
    "                corr = rating_corr[1]\n",
    "                weighted_sum += rating * corr\n",
    "                weight_sum += corr\n",
    "            if count < min_neighbour_count:         # if less than min_neighbour_count neighbour found, pass\n",
    "                continue\n",
    "            prediction = weighted_sum / weight_sum\n",
    "            actual = trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "            predictions.append( (movie_id, (prediction, actual) ) )\n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movies_watched(timebin, trainset, user_id):\n",
    "        movies_watched = timebin.index.to_list()\n",
    "        predictions = list()\n",
    "        for movie in movies_watched:\n",
    "            prediction = trainset.predict_movie(user_id=user_id, movie_id=movie, k=10)\n",
    "            \n",
    "            if prediction != 0:\n",
    "                actual = trainset.trainset_movie.get_movie_rating(movie_id=movie, user_id=user_id)\n",
    "                predictions.append((prediction, actual))\n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_timebin_size(tc: TimeConstraint):\n",
    "        return abs((tc.start_dt - tc.end_dt).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimebinSimilarityV6:\n",
    "    \"\"\"\n",
    "    TembinSimilarity is a way to provide personalized timebin based recommendations.\n",
    "    Here we define an alternative to classical pearson by providing temporal aspect.\n",
    "    Here is what we do in summary:\n",
    "      1. Choose a person to make prediction on (as always).\n",
    "      2. Take the last s movie ratings of this person as a timebin from a random timepoint.(user must have at least s movie watched before!)\n",
    "      3. Find neighbour timebins to the selected timebin.(using correlations between them, higher, better)\n",
    "      4. Predict rating for user using the timebin neighbours the same way as we use in k nearest neighbour.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings, trainset, k=5, r=3, s=10, p=3, corr_threshold=0.5, \n",
    "                 neighbour_min_s=5, neighbour_max_s=50, neighbour_step_size=5):\n",
    "        \"\"\"\n",
    "        :param k: Minimum number of ratings in common in between neighbour users when taking timebins of them. \n",
    "        :param r: Minimum number of ratings in common between neighbour timebins.\n",
    "        :param s: Maximum number of movies to include inside of the timebin.\n",
    "        :param p: Minimum number of neighbour timebins when making prediction.\n",
    "        :param neighbour_min_s: Minimum number of movies to include inside neighbour timebins\n",
    "        :param neighbour_max_s: Maximum number of movies to include inside neighbour timebins\n",
    "        :param neighbour_step_size: Number of movies to extend per step the timebin size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.ratings.sort_values(['user_id', 'timestamp'], ignore_index=True, inplace=True)\n",
    "        self.trainset = trainset\n",
    "        self.k = k\n",
    "        self.r = r\n",
    "        self.s = s\n",
    "        self.p = p\n",
    "        self.corr_threshold = corr_threshold\n",
    "        \n",
    "        self.neighbour_min_s = neighbour_min_s\n",
    "        self.neighbour_max_s = neighbour_max_s\n",
    "        self.neighbour_step_size = neighbour_step_size\n",
    "        \n",
    "        if s < 1:\n",
    "            raise Exception(\"Timebin size must be positive.\")\n",
    "        \n",
    "        # For ease of use, save these\n",
    "        self.trainset_user = trainset.trainset_user\n",
    "        self.trainset_movie = trainset.trainset_movie\n",
    "        self.first_timestamp = ratings['timestamp'].min()\n",
    "                \n",
    "        # Set these before calculating any correlations\n",
    "        self.user_id = None\n",
    "        self.timebin = None\n",
    "        self.timebin_user_avg_rating = None\n",
    "       \n",
    "    def find_timebin_corr(self, merged:pd.DataFrame, neighbour_avg_rating):\n",
    "        \"\"\"\n",
    "        Find the correlation between the given neighbour timebin and the self.timebin\n",
    "        \n",
    "        :param merged: Merged version of neighbour timebin and self.timebin\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate Pearson Correlation in between the self.timebin and given neighbour\n",
    "        numenator = ((merged['rating_x'] - self.timebin_user_avg_rating) * (merged['rating_y'] - neighbour_avg_rating)).sum()\n",
    "        denominator = math.sqrt(((merged['rating_x'] - self.timebin_user_avg_rating) ** 2).sum())\n",
    "        denominator *= math.sqrt(((merged['rating_y'] - neighbour_avg_rating) ** 2).sum())\n",
    "        pearson = numenator / denominator\n",
    "        \n",
    "        return pearson\n",
    "        \n",
    "    \n",
    "    def get_movies_watched(self, user_id: int, time_constraint: TimeConstraint = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the movies watched by the chosen user.\n",
    "\n",
    "        :param user_id: the user that we want to get the movies he-she has watched.\n",
    "        :param time_constraint: type of the time constraint.\n",
    "        :return: DataFrame of all movies watched with 'item_id', 'rating' columns\n",
    "        \"\"\"\n",
    "\n",
    "        movie_ratings = self.ratings\n",
    "\n",
    "        if time_constraint is None:\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "        elif time_constraint.is_valid_time_bin():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "        return None   # Means the Time_constraint is not a valid timebin!\n",
    "    \n",
    "    def get_timebin2(self, user_id, timebin_i, timebin_size):\n",
    "        \"\"\"\n",
    "        Generate the timebin by using given info.\n",
    "        timebin_i is the index the first movie\n",
    "        timebin_size is the number of movies to take starting at timebin_i th index.\n",
    "        \"\"\"\n",
    "        all_movies_watched = self.get_movies_watched(user_id)\n",
    "        return all_movies_watched.iloc[timebin_i:timebin_i+timebin_size]\n",
    "    \n",
    "    def get_timebin3(self, user_id, timebin_i, timebin_size, i):\n",
    "        \"\"\"\n",
    "        Remove the i th rating from the timebin while regenerating the timebin.\n",
    "        \"\"\"\n",
    "        all_movies_watched = self.get_movies_watched(user_id)\n",
    "        original_timebin = all_movies_watched.iloc[timebin_i:timebin_i+timebin_size] \n",
    "        return pd.concat([original_timebin.iloc[0:i], original_timebin.iloc[i+1:]])\n",
    "    \n",
    "    \n",
    "    def get_neighbour_timebins_with_the_movie(self, neighbour_id:int, movie_id:int)->list:\n",
    "        \"\"\"\n",
    "        Given a neighbour_id, take the all the timebins of this neighbour which includes the given movie.\n",
    "        \"\"\"\n",
    "        # Start by taking all movies watched by the neighbour\n",
    "        all_movies_watched = self.get_movies_watched(neighbour_id)\n",
    "        n_movies = len(all_movies_watched)\n",
    "        neighbour_timebins = list()\n",
    "\n",
    "        # For each timebin_size\n",
    "        for timebin_size in range(self.neighbour_min_s, self.neighbour_max_s, self.neighbour_step_size):\n",
    "            # Traverse the all movies by taking 'timebin_size' piece of ratings per loop\n",
    "            for i in range(0, n_movies, timebin_size):\n",
    "                timebin = all_movies_watched.iloc[i:i+timebin_size]\n",
    "                # Take only timebins which includes this movie\n",
    "                if not (movie_id in timebin.index):\n",
    "                    continue\n",
    "                # Insert the timebin, its index i, and its size timebin_size into the list as a tuple\n",
    "                neighbour_timebins.append(  (timebin, i, timebin_size)  )\n",
    "        return neighbour_timebins\n",
    "\n",
    "    def get_timebin_neighbours_with_the_movie(self, user_id:int, timebin_i, timebin_size, i):\n",
    "        ratings = self.ratings\n",
    "        # Recreate the user timebin using its identifiers\n",
    "        timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "        movie_id = self.timebin.index[i]\n",
    "        # !!!!! ratings'de son filmden sonrakileri tahminlari alma\n",
    "        # Count number of common ratings with other users\n",
    "        userlist = [0 for i in range(611)]\n",
    "        for movie_id in timebin.index.values.tolist():\n",
    "            users_who_watched = ratings.loc[(ratings['item_id'] == movie_id)][['user_id']].values.tolist()\n",
    "            for user_who_watched in users_who_watched:\n",
    "                userlist[user_who_watched[0]] += 1\n",
    "\n",
    "        # save as neighbour, if common rating count greater than k and given rating to the movie index at i\n",
    "        neighbour_id_list = []\n",
    "        for j in range(0, 611):\n",
    "            if( (userlist[j] > self.k) and \n",
    "               (self.trainset_movie.get_movie_rating(user_id=j, movie_id=movie_id) != 0) and \n",
    "               (j != user_id) ):\n",
    "                neighbour_id_list.append(j)\n",
    "\n",
    "        return neighbour_id_list\n",
    "                 \n",
    "    def get_similar_timebins(self, user_id, timebin_i, timebin_size, i):\n",
    "        \"\"\"\n",
    "        :param timebin_i: timebin identifier, identifies start of timebin\n",
    "        :param timebin_size: timebin identifies, identifies size of the timebin starting at timebin_i\n",
    "        :param i: index of the movie of interest inside of the identified timebin\n",
    "        \"\"\"\n",
    "        # Recreate the user timebin using its identifiers\n",
    "        timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "        time_constraint = TimeConstraint(end_dt=timebin.iloc[len(timebin)-1]['timestamp'])\n",
    "        # Neighbours contains users who has rated self.k movies in common and also rated the ith movie\n",
    "        neighbours = self.get_timebin_neighbours_with_the_movie(user_id, timebin_i, timebin_size, i)\n",
    "\n",
    "        data = list()\n",
    "        for neighbour_id in neighbours:\n",
    "            neighbour_timebins = self.get_neighbour_timebins_with_the_movie(neighbour_id=neighbour_id, movie_id=self.timebin.index[i])\n",
    "            \n",
    "            # For each neighbour timebin, calculate pearson between the timebin and neighbour timebin \n",
    "            for neighbour_timebin, timebin_i, timebin_size in neighbour_timebins:\n",
    "                \n",
    "                neighbour_time_constraint = TimeConstraint(end_dt=neighbour_timebin.iloc[len(timebin)-1]['timestamp'])\n",
    "                neighbour_avg_rating = self.trainset_user.get_user_avg_at(neighbour_id, neighbour_time_constraint)\n",
    "            \n",
    "                \n",
    "                # Filter unrelated movie ratings and only keep common movie ratings\n",
    "                merged = neighbour_timebin.merge(self.timebin, on='item_id')\n",
    "                common_elements = len(merged)\n",
    "\n",
    "                # If less than self.r movies in common rated in the neighbour_timebin, dont process this timebin\n",
    "                if common_elements < self.r:\n",
    "                    continue\n",
    "\n",
    "                # Calculate Pearson Correlation between neighbour timebin and self.timebin\n",
    "                corr = self.find_timebin_corr(merged, neighbour_avg_rating)\n",
    "\n",
    "                # Dont include the neighbour timebin if corr is invalid or less than corr_threshold\n",
    "                if math.isnan(corr) or corr < self.corr_threshold:                     \n",
    "                    continue\n",
    "\n",
    "                binsize_in_days = TimebinSimilarity.get_timebin_size(\n",
    "                                    TimeConstraint(start_dt=neighbour_timebin.iloc[0]['timestamp'], \n",
    "                                                   end_dt=neighbour_timebin.iloc[len(neighbour_timebin)-1]['timestamp']))\n",
    "\n",
    "                data.append( (neighbour_id, common_elements, corr, timebin_i, timebin_size, binsize_in_days) )\n",
    "\n",
    "        return pd.DataFrame(data, columns=['neighbour_id', 'n_common','pearson_corr', 'timebin_i', 'timebin_size', 'timebin_size_in_days'])\n",
    "\n",
    "    def get_timebin_neighbours_data_for_no_bias(self, similar_timebins, movie_id):\n",
    "        \"\"\"\n",
    "            Collect neighbour ratings to the movie with id 'movie_id'.\n",
    "        \"\"\"\n",
    "        data = list()\n",
    "        \n",
    "        for row in similar_timebins.itertuples(index=False):\n",
    "            # Get neighbour timebin data\n",
    "            neighbour_id = row[0]\n",
    "            n_common = row[1]\n",
    "            corr = row[2]\n",
    "            timebin_i = row[3]\n",
    "            timebin_size = row[4]\n",
    "            timebin_size_in_days = row[5]\n",
    "            \n",
    "            # Create the neighbour timebin from its data\n",
    "            neighbour_bin = self.get_timebin2(neighbour_id, timebin_i, timebin_size)\n",
    "            rating = None\n",
    "            try: \n",
    "                rating = neighbour_bin.loc[movie_id]     # test whether the neighbour has rating for the item\n",
    "            except KeyError:\n",
    "                continue                                 # if neighbour dont have rating for the item, then pass this round of loop\n",
    "            \n",
    "            # insert rating for the neighbour into data \n",
    "            #  and also insert other data identifying the neighbour(for in case we use them in analysis)\n",
    "            if rating is not None:\n",
    "                data.append( (rating[0], corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days) )\n",
    "        \n",
    "        return data \n",
    "    \n",
    "    def analize_timebin_prediction(self, n_users):\n",
    "        output = list()\n",
    "        \n",
    "        # collected data count\n",
    "        count = 0\n",
    "        \n",
    "        while count < n_users:\n",
    "            # Choose a random user\n",
    "            user_id = random.randint(0,610)\n",
    "            \n",
    "            ### Choose Random timebin\n",
    "            \n",
    "            # Get all movies that has been watched by the user\n",
    "            movies_watched = self.get_movies_watched(user_id)\n",
    "            \n",
    "            # take a random starting point and take self.s piece movies starting from that point\n",
    "            max_movie_index = ( len(movies_watched) - 1 ) - self.s\n",
    "            if max_movie_index <= 0:\n",
    "                continue\n",
    "            timebin_i = random.randint(0, max_movie_index)\n",
    "            timebin = self.get_timebin2(user_id, timebin_i, self.s)\n",
    "            \n",
    "            # Get max limit time constraint where max limit is the time we rate the last movie inside the timebin\n",
    "            time_constraint = TimeConstraint(end_dt=timebin.iloc[len(timebin)-1]['timestamp'])\n",
    "            \n",
    "            # This is saved because we need to get the movie_id which is found at index i\n",
    "            self.timebin = timebin\n",
    "            \n",
    "            # Used for correlation calculations\n",
    "            self.user_id = user_id\n",
    "            self.timebin_user_avg_rating = self.trainset_user.get_user_avg_at(user_id, time_constraint)\n",
    "            \n",
    "            timebin_size = len(timebin)\n",
    "            \n",
    "            # Make sure we have a valid timebin before moving forward\n",
    "            if timebin is None or len(timebin) < self.r:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction without timebins\n",
    "            \n",
    "            # Predict all the movies inside of the timebin by the classic way,using pearson correlation\n",
    "            normal_predictions = TimebinSimilarity.predict_movies_watched(timebin=timebin, trainset = self.trainset, \n",
    "                                                                          user_id=user_id)\n",
    "            normal_rmse = Accuracy.rmse(normal_predictions)\n",
    "            normal_threshold_accuracy  = Accuracy.threshold_accuracy(normal_predictions)\n",
    "            \n",
    "            # In case we are not able to make predictions without using timebins\n",
    "            # dont make any further processing since we can not compare 0 with timebin rmse \n",
    "            if normal_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            ### Make prediction with timebins\n",
    "            \n",
    "            # Save all the predictions made for the current user\n",
    "            predictions = list()\n",
    "            # Here we will be removing each movie from timebin\n",
    "            # then find similar timebin to the new version of the timebin\n",
    "            # use the neighbours and their correlation to make movie prediction on the selected movie\n",
    "            for i in range(timebin_size):   # i stands for the index of the movie found in the timebin\n",
    "                \n",
    "                ##### her filmden nceki son 20 filmi al\n",
    "                \n",
    "                similar_timebins = self.get_similar_timebins(user_id, timebin_i, timebin_size, i)\n",
    "                if similar_timebins.empty:\n",
    "                    continue  \n",
    "                    \n",
    "                # Drop duplicate (neighbour_id, n_common, pearson_corr, timebin_i, timebin_size) tuples so that now no repeating timebin exists\n",
    "                similar_timebins.drop_duplicates(['neighbour_id','n_common', 'pearson_corr', 'timebin_i'], inplace=True)\n",
    "                \n",
    "                movie_id = timebin.index[i]\n",
    "                \n",
    "                # collect neighbour ratings for the movie as well as neighbour correlations between the timebin\n",
    "                data = self.get_timebin_neighbours_data_for_no_bias(similar_timebins, movie_id)\n",
    "                \n",
    "                prediction = TimebinSimilarity.predict_movie(data, k=10, min_neighbour_count = self.p)\n",
    "                actual = self.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "                print(movie_id, prediction, actual)\n",
    "                predictions.append( (prediction, actual) )\n",
    "            \n",
    "            timebins_rmse = Accuracy.rmse(predictions)\n",
    "            timebin_threshold_accuracy = Accuracy.threshold_accuracy(predictions)\n",
    "            \n",
    "            # In case timebin_rmse is 0 continue since we can not compare with normal rmse\n",
    "            if timebins_rmse == 0:\n",
    "                continue\n",
    "            \n",
    "            # Debug output\n",
    "            print(f\"Normal RMSE: {normal_rmse:.2} Timebin RMSE:{timebins_rmse:.2} \\\n",
    "                    Normal Threshold Acc: {int(normal_threshold_accuracy)}% Timebin Threshold Acc: {int(timebin_threshold_accuracy)}%\")\n",
    "\n",
    "            # Save the data\n",
    "#             output.append( ((normal_rmse, timebins_rmse), \n",
    "#                             (normal_threshold_accuracy, timebin_threshold_accuracy), \n",
    "#                             user_id, timebin_i, timebin_size, \n",
    "#                             data) )\n",
    "            # we saved a data succesfully, increment collected data cout \n",
    "            count += 1\n",
    "            \n",
    "        return output       \n",
    "            \n",
    "    def get_timebin_neighbours_data(self, timebin, similar_timebins):\n",
    "        \"\"\"\n",
    "        Get timebin possessors' ratings and timebin correlations as the output\n",
    "        \"\"\"\n",
    "        # Store data in order to return as result\n",
    "        data = defaultdict(list)\n",
    "        for row in similar_timebins.itertuples(index=False):\n",
    "            # Get neighbour timebin data\n",
    "            neighbour_id = row[0]\n",
    "            n_common = row[1]\n",
    "            corr = row[2]\n",
    "            timebin_i = row[3]\n",
    "            timebin_size = row[4]\n",
    "            timebin_size_in_days = row[5]\n",
    "            \n",
    "            # Create the neighbour timebin from its data\n",
    "            neighbour_bin = self.get_timebin2(neighbour_id, timebin_i, timebin_size)\n",
    "            \n",
    "            # Get rid of movie ratings of the neighbour that are not found in the timebin\n",
    "            merged_bin = pd.merge(timebin, neighbour_bin, left_index=True, right_index=True)\n",
    "            \n",
    "            # For each common movie rating, store neighbour rating and its correlation to the timebin\n",
    "            for bin_row in merged_bin.itertuples(index=True):\n",
    "                curr_movie = bin_row[0]\n",
    "                neighbour_rating = bin_row[3]\n",
    "                #print(bin_row[0], bin_row[1], bin_row[2], bin_row[3], bin_row[4])\n",
    "                data[curr_movie].append( (neighbour_rating, corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days) )\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movie_with_user_corrs(movie_id, similar_timebins, trainset_movie, k=10, min_neighbour_count=5):\n",
    "        neighbours_data = similar_timebins[['neighbour_id', 'pearson_corr']].groupby('neighbour_id').mean()\n",
    "        neighbours_data.sort_values(by='pearson_corr', ascending=False, inplace=True)\n",
    "        \n",
    "        weighted_sum = 0\n",
    "        weight_sum = 0\n",
    "        count = 0\n",
    "        for index, row in similar_timebins[['neighbour_id', 'pearson_corr']].groupby('neighbour_id').mean().iterrows():\n",
    "            neighbour_id = index\n",
    "            corr = row[0]\n",
    "            rating = trainset_movie.get_movie_rating(neighbour_id, movie_id)\n",
    "            weighted_sum += rating * corr\n",
    "            weight_sum += corr\n",
    "            # Only take k nearest neighbours\n",
    "            if count == k:\n",
    "                break\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "        if count < min_neighbour_count:\n",
    "            return 0\n",
    "        \n",
    "        prediction = weighted_sum / weight_sum\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_movie(data, k=10,  min_neighbour_count=5):\n",
    "        \"\"\"\n",
    "        Make prediction by using the neighbour timebin data on the movie of interest.\n",
    "        K nearest neighbours is used only.\n",
    "        \"\"\"\n",
    "        # Sort the data by corr\n",
    "        data.sort(key=lambda data_element: data_element[1])\n",
    "        \n",
    "        # each row of data ->(rating, corr, neighbour_id, n_common, timebin_i, timebin_size, timebin_size_in_days)\n",
    "        weighted_sum = 0\n",
    "        weight_sum = 0\n",
    "        count = 0\n",
    "        for (rating, corr, _, _, _, _, _) in data:\n",
    "            weighted_sum += rating * corr\n",
    "            weight_sum += corr\n",
    "            \n",
    "            # Only take k neighbours\n",
    "            if count == k:\n",
    "                break\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "        if count < min_neighbour_count:\n",
    "            return 0\n",
    "        \n",
    "        prediction = weighted_sum / weight_sum\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_timebin_size(tc: TimeConstraint):\n",
    "        return abs((tc.start_dt - tc.end_dt).days)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MovieLensDataset(is_movies_cached=True, is_ratings_cached=True)\n",
    "timebin_similarity = TimebinSimilarityV6(ratings=dataset.ratings, trainset=t, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 0 1.0\n",
      "1269 0 2.5\n",
      "2918 0 1.5\n",
      "140 3.0000000000000004 3.0\n",
      "628 0 3.0\n",
      "661 3.0000000000000004 3.0\n",
      "100 0 4.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.001                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yukawa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 0 3.0\n",
      "39 0 3.0\n",
      "32 0 4.0\n",
      "50 0 5.0\n",
      "266 0 5.0\n",
      "432 0 3.0\n",
      "168 5.0 5.0\n",
      "186 3.0 4.0\n",
      "204 4.0 4.0\n",
      "Normal RMSE: 0.6 Timebin RMSE:0.33                     Normal Threshold Acc: 80% Timebin Threshold Acc: 66%\n",
      "2858 4.999999999999999 4.0\n",
      "1258 4.68285238726833 4.0\n",
      "541 4.10905806257681 3.5\n",
      "1206 4.777683313404955 5.0\n",
      "3949 0 4.5\n",
      "Normal RMSE: 0.17 Timebin RMSE:0.38                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "58559 0 5.0\n",
      "44191 0 5.0\n",
      "435 0 0.5\n",
      "466 0 2.0\n",
      "1234 0 4.0\n",
      "260 4.950732753376498 5.0\n",
      "1196 5.0 5.0\n",
      "1198 5.0 5.0\n",
      "318 0 5.0\n",
      "2571 4.840293692034101 5.0\n",
      "1210 5.0 5.0\n",
      "7153 5.0 5.0\n",
      "1291 0 5.0\n",
      "Normal RMSE: 0.001 Timebin RMSE:0.001                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "1222 0 2.0\n",
      "2028 0 2.0\n",
      "4011 0 3.0\n",
      "231 3.5000000000000004 2.0\n",
      "104 3.0 3.0\n",
      "480 0 2.0\n",
      "1391 0.7064551721981309 0.5\n",
      "3081 0 4.0\n",
      "3827 1.0 1.5\n",
      "1997 0 2.5\n",
      "Normal RMSE: 0.38 Timebin RMSE:0.62                     Normal Threshold Acc: 100% Timebin Threshold Acc: 75%\n",
      "58559 5.0 5.0\n",
      "1196 4.499999999999999 3.5\n",
      "260 4.499999999999999 3.5\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.67                     Normal Threshold Acc: 83% Timebin Threshold Acc: 100%\n",
      "296 4.863162867235526 4.5\n",
      "2959 4.805930194170472 5.0\n",
      "48516 4.73397848028866 4.0\n",
      "293 4.557514777381712 5.0\n",
      "47 4.685942957865985 5.0\n",
      "1213 4.722823239348721 4.5\n",
      "858 4.81769780604438 5.0\n",
      "1221 4.458587086520191 5.0\n",
      "1097 4.411772716898281 4.0\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.17                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "1 0 3.0\n",
      "173 0 3.0\n",
      "196 0 3.0\n",
      "4011 4.16299729840672 5.0\n",
      "3499 3.1131830052788763 4.5\n",
      "110 4.321166895568267 5.0\n",
      "3994 4.309904974217835 4.5\n",
      "4848 0 5.0\n",
      "6539 3.9552791806712024 4.0\n",
      "2571 4.81217289031404 4.5\n",
      "7361 4.249992800848129 5.0\n",
      "Normal RMSE: 0.46 Timebin RMSE:0.68                     Normal Threshold Acc: 83% Timebin Threshold Acc: 85%\n",
      "99114 4.79326301853358 4.5\n",
      "2959 4.482606676642277 4.5\n",
      "91529 3.913544268091011 3.5\n",
      "4011 4.278169706713275 4.0\n",
      "608 3.4675067127848944 3.0\n",
      "296 4.278204951582858 3.5\n",
      "1206 4.322177005018937 4.0\n",
      "72998 2.235982945222019 3.0\n",
      "356 4.457922200833248 3.5\n",
      "Normal RMSE: 0.17 Timebin RMSE:0.47                     Normal Threshold Acc: 83% Timebin Threshold Acc: 100%\n",
      "1517 4.0 4.0\n",
      "2683 3.8411620430954345 4.0\n",
      "2329 4.689181184156636 4.5\n",
      "1784 3.854021395668811 4.0\n",
      "3147 4.33952087331923 4.5\n",
      "1961 4.277055567819091 4.0\n",
      "608 4.579017902856232 5.0\n",
      "50 4.695783344852002 4.5\n",
      "318 4.7509694257457555 4.5\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.083                     Normal Threshold Acc: 87% Timebin Threshold Acc: 100%\n",
      "922 5.000000000000001 4.0\n",
      "1252 4.713787852943566 5.0\n",
      "1617 4.578066630421977 4.0\n",
      "913 4.297349376165469 5.0\n",
      "2987 2.7862327179246047 1.0\n",
      "858 4.865211733602365 5.0\n",
      "527 4.585093894059298 5.0\n",
      "750 5.0 5.0\n",
      "912 4.961043533138126 5.0\n",
      "1233 4.705140755285634 5.0\n",
      "Normal RMSE: 0.001 Timebin RMSE:0.62                     Normal Threshold Acc: 100% Timebin Threshold Acc: 90%\n",
      "50 1.5460663837824167 2.0\n",
      "161 3.7426022650141966 5.0\n",
      "457 4.523889509804805 5.0\n",
      "474 4.0 4.0\n",
      "10 3.1743908707351234 4.0\n",
      "165 3.3273802504208208 3.0\n",
      "185 3.3568198125775575 3.0\n",
      "367 3.8996551658048104 5.0\n",
      "480 4.0351933894865635 4.0\n",
      "508 0 3.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.58                     Normal Threshold Acc: 66% Timebin Threshold Acc: 88%\n",
      "2028 5.0 5.0\n",
      "1242 4.0 5.0\n",
      "2944 5.0 4.0\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.67                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "2916 0 3.0\n",
      "34 0 2.0\n",
      "1200 0 3.0\n",
      "539 0 2.5\n",
      "2291 3.2421116848167464 3.5\n",
      "2174 2.8679474233130793 3.0\n",
      "Normal RMSE: 0.025 Timebin RMSE:0.12                     Normal Threshold Acc: 100% Timebin Threshold Acc: 50%\n",
      "260 3.5916386795777653 3.0\n",
      "1196 3.785979341661072 3.0\n",
      "1198 4.261159286933738 3.5\n",
      "1036 4.787408375497795 5.0\n",
      "1210 3.907669143132486 3.0\n",
      "648 4.171700701584211 5.0\n",
      "344 4.7464525669028745 4.0\n",
      "4306 4.056188843713198 4.5\n",
      "1721 3.265993836687762 3.5\n",
      "165 4.34083985102927 5.0\n",
      "Normal RMSE: 0.2 Timebin RMSE:0.5                     Normal Threshold Acc: 90% Timebin Threshold Acc: 60%\n",
      "2605 3.0010877275765178 2.0\n",
      "2628 3.598116020361197 3.0\n",
      "2683 2.055022889556792 1.0\n",
      "2712 3.28771788181921 1.0\n",
      "318 4.5 5.0\n",
      "1617 0 5.0\n",
      "1537 0 4.0\n",
      "296 4.4985682107056535 3.0\n",
      "356 3.8037590057904107 4.0\n",
      "1 3.9244533478965256 4.0\n",
      "Normal RMSE: 0.32 Timebin RMSE:1.4                     Normal Threshold Acc: 85% Timebin Threshold Acc: 75%\n",
      "4995 0 3.0\n",
      "4027 0 3.0\n",
      "3481 0 3.5\n",
      "2423 0 2.0\n",
      "1127 3.0 3.0\n",
      "2858 0 4.0\n",
      "2683 0 5.0\n",
      "2706 0 5.0\n",
      "2707 3.0 3.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.001                     Normal Threshold Acc: 85% Timebin Threshold Acc: 100%\n",
      "733 4.889396653226239 5.0\n",
      "786 5.0 4.0\n",
      "1073 3.079689635464993 3.0\n",
      "104 3.289226283368602 3.0\n",
      "260 4.536555531395447 5.0\n",
      "653 4.0 4.0\n",
      "708 3.6280315980010083 3.0\n",
      "788 3.0000000000000004 4.0\n",
      "Normal RMSE: 0.69 Timebin RMSE:0.34                     Normal Threshold Acc: 55% Timebin Threshold Acc: 75%\n",
      "3 0 3.0\n",
      "5 0 3.0\n",
      "7 0 3.0\n",
      "1307 4.0 3.5\n",
      "1 4.5 4.5\n",
      "1968 0 4.0\n",
      "6377 4.999999999999999 5.0\n",
      "48738 4.5 4.5\n",
      "Normal RMSE: 0.71 Timebin RMSE:0.062                     Normal Threshold Acc: 83% Timebin Threshold Acc: 100%\n",
      "1273 0 5.0\n",
      "1394 5.0 5.0\n",
      "2076 5.0 5.0\n",
      "1189 0 4.0\n",
      "2919 3.0 3.0\n",
      "Normal RMSE: 0.42 Timebin RMSE:0.001                     Normal Threshold Acc: 83% Timebin Threshold Acc: 100%\n",
      "1198 0 5.0\n",
      "2951 4.32024599598819 4.0\n",
      "480 3.0 3.0\n",
      "2916 4.0 5.0\n",
      "3175 0 4.0\n",
      "1580 4.0 4.0\n",
      "Normal RMSE: 0.38 Timebin RMSE:0.31                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "153 2.7515861137053816 3.0\n",
      "165 3.9208865591129562 4.0\n",
      "344 2.448171037870041 3.0\n",
      "349 3.4408461417424996 3.0\n",
      "434 2.859777628175144 2.0\n",
      "457 4.099656853913778 4.0\n",
      "593 4.565814105883619 4.0\n",
      "10 3.2333697592937845 3.0\n",
      "185 2.1498972789062982 3.0\n",
      "208 2.1685672364616715 2.0\n",
      "Normal RMSE: 0.21 Timebin RMSE:0.28                     Normal Threshold Acc: 66% Timebin Threshold Acc: 100%\n",
      "110 4.294200765519485 4.5\n",
      "356 4.999999999999999 4.5\n",
      "608 4.270928640979948 5.0\n",
      "44191 4.3719873598386405 4.0\n",
      "59315 4.0930930830729135 4.0\n",
      "480 3.9927888212495724 5.0\n",
      "8636 3.160085630298016 2.5\n",
      "150 4.079265810153723 5.0\n",
      "3793 4.118654988065654 4.5\n",
      "4886 4.273327292754702 4.5\n",
      "Normal RMSE: 1.4 Timebin RMSE:0.33                     Normal Threshold Acc: 80% Timebin Threshold Acc: 100%\n",
      "318 4.415131461216215 4.0\n",
      "356 4.83763344871245 4.0\n",
      "2028 4.887186780173313 4.5\n",
      "4022 4.465814197089169 4.5\n",
      "168252 0 4.5\n",
      "110 4.2249398389615465 4.0\n",
      "70286 5.0 4.0\n",
      "2571 4.939436809547352 4.5\n",
      "Normal RMSE: 0.16 Timebin RMSE:0.39                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "780 3.2685682172764605 3.0\n",
      "733 4.0 4.0\n",
      "2396 3.975744387479887 4.0\n",
      "527 4.556514130972814 5.0\n",
      "2028 4.385554132179873 4.0\n",
      "296 4.303295491053103 5.0\n",
      "1617 4.2885580373322085 5.0\n",
      "2858 4.807271533984845 5.0\n",
      "Normal RMSE: 0.33 Timebin RMSE:0.16                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "95 2.259218161394509 3.0\n",
      "141 3.705674976383354 4.0\n",
      "648 3.4026711342678673 3.0\n",
      "736 3.5596294761675904 3.0\n",
      "780 3.6316090533119003 3.0\n",
      "7 2.9999999999999996 4.0\n",
      "36 4.439923393492909 5.0\n",
      "608 4.999999999999999 5.0\n",
      "733 3.091259865198314 3.0\n",
      "14 4.377385839815987 4.0\n",
      "Normal RMSE: 0.17 Timebin RMSE:0.28                     Normal Threshold Acc: 90% Timebin Threshold Acc: 70%\n",
      "539 0 4.0\n",
      "150 0 4.0\n",
      "1246 0 5.0\n",
      "5952 0 0.5\n",
      "4995 0 5.0\n",
      "48516 4.5 5.0\n",
      "3578 0 5.0\n",
      "1246 4.0 5.0\n",
      "63082 4.0 5.0\n",
      "Normal RMSE: 0.62 Timebin RMSE:0.75                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "235 4.0 5.0\n",
      "265 5.000000000000001 4.0\n",
      "6 5.000000000000001 4.0\n",
      "16 4.0 4.0\n",
      "273 5.0 4.0\n",
      "431 5.0 4.0\n",
      "509 4.0 4.0\n",
      "Normal RMSE: 0.75 Timebin RMSE:0.71                     Normal Threshold Acc: 83% Timebin Threshold Acc: 71%\n",
      "4027 2.0 2.5\n",
      "5669 3.4999999999999996 4.5\n",
      "8798 2.4999999999999996 4.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:1.2                     Normal Threshold Acc: 33% Timebin Threshold Acc: 33%\n",
      "2329 4.221596012037418 5.0\n",
      "79132 0 2.0\n",
      "92259 0 2.0\n",
      "858 4.0068782570990535 4.0\n",
      "2959 3.9055283373720635 4.0\n",
      "2858 4.403818010105735 4.0\n",
      "750 4.384721630127231 4.0\n",
      "68954 3.815088956377935 5.0\n",
      "Normal RMSE: 0.88 Timebin RMSE:0.42                     Normal Threshold Acc: 87% Timebin Threshold Acc: 100%\n",
      "762 0 2.0\n",
      "296 4.7371624949155855 5.0\n",
      "457 4.416620750684149 4.0\n",
      "110 4.7371624949155855 4.0\n",
      "Normal RMSE: 0.075 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "1320 2.818386411454253 1.5\n",
      "4995 4.0 3.5\n",
      "3753 3.406518401390681 1.0\n",
      "296 3.7388034065912987 4.5\n",
      "356 4.223164889220024 5.0\n",
      "480 4.224292154618044 5.0\n",
      "457 4.724174441211313 4.5\n",
      "318 5.0 5.0\n",
      "150 4.038724870363609 5.0\n",
      "110 4.828704546259928 4.0\n",
      "Normal RMSE: 1.4 Timebin RMSE:1.4                     Normal Threshold Acc: 90% Timebin Threshold Acc: 100%\n",
      "1224 2.0 3.0\n",
      "1273 0 5.0\n",
      "1394 5.000000000000001 5.0\n",
      "2076 5.000000000000001 5.0\n",
      "1189 0 4.0\n",
      "1199 5.000000000000001 5.0\n",
      "Normal RMSE: 0.3 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 25%\n",
      "2080 4.0 4.0\n",
      "1265 5.0 5.0\n",
      "969 0 1.0\n",
      "377 0 4.0\n",
      "1197 5.000000000000001 5.0\n",
      "Normal RMSE: 1.6 Timebin RMSE:0.001                     Normal Threshold Acc: 85% Timebin Threshold Acc: 66%\n",
      "1961 4.0 5.0\n",
      "2918 3.5000000000000004 4.0\n",
      "1221 4.665986286863405 5.0\n",
      "608 4.820532107747486 4.0\n",
      "1196 4.3782295207972535 4.0\n",
      "1213 5.000000000000001 5.0\n",
      "296 5.000000000000001 4.0\n",
      "1104 4.442943979955326 4.0\n",
      "25 0 2.0\n",
      "Normal RMSE: 0.1 Timebin RMSE:0.5                     Normal Threshold Acc: 100% Timebin Threshold Acc: 75%\n",
      "1240 4.360793519863093 5.0\n",
      "480 0 5.0\n",
      "1201 0 5.0\n",
      "3527 0 5.0\n",
      "3578 0 5.0\n",
      "592 3.6226200420867745 3.0\n",
      "Normal RMSE: 0.1 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 50%\n",
      "1288 3.4999999999999996 4.5\n",
      "2599 2.5 1.5\n",
      "1500 3.0 2.0\n",
      "370 0 3.5\n",
      "Normal RMSE: 1.3 Timebin RMSE:1.0                     Normal Threshold Acc: 80% Timebin Threshold Acc: 66%\n",
      "912 0 4.5\n",
      "2336 0 3.5\n",
      "3735 0 3.0\n",
      "480 4.450464042304543 4.0\n",
      "208 2.8990026040981665 3.0\n",
      "339 4.087919065107231 4.0\n",
      "454 4.0 5.0\n",
      "300 3.6382835106730322 3.0\n",
      "377 3.549028472991765 3.0\n",
      "500 3.1705538367929025 3.0\n",
      "586 2.4431876953476444 3.0\n",
      "587 4.1894255911153415 5.0\n",
      "597 3.8237615656383035 4.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.3                     Normal Threshold Acc: 90% Timebin Threshold Acc: 80%\n",
      "2959 4.0991765652946945 3.0\n",
      "260 4.524455074977425 5.0\n",
      "1198 4.002704519521333 2.0\n",
      "1196 4.716513291879433 4.5\n",
      "1197 3.8939920521452343 3.0\n",
      "527 4.578241335771926 4.0\n",
      "6016 0 4.0\n",
      "296 4.822530348435811 4.0\n",
      "7153 4.442469850781548 4.0\n",
      "1193 4.591482199650088 5.0\n",
      "Normal RMSE: 0.97 Timebin RMSE:0.89                     Normal Threshold Acc: 75% Timebin Threshold Acc: 66%\n",
      "344 2.9866405394438975 3.0\n",
      "231 2.7779838896776132 3.0\n",
      "316 3.863854508545132 4.0\n",
      "318 4.417061417124659 4.0\n",
      "595 5.0 5.0\n",
      "10 3.0845214419636537 3.0\n",
      "161 3.876138392637557 3.0\n",
      "292 4.0 5.0\n",
      "339 4.278791093559013 5.0\n",
      "434 4.0 4.0\n",
      "Normal RMSE: 0.43 Timebin RMSE:0.25                     Normal Threshold Acc: 85% Timebin Threshold Acc: 90%\n",
      "588 4.198968389878759 4.0\n",
      "231 2.0324389138928955 3.0\n",
      "349 4.433044674780893 4.0\n",
      "595 4.093468151592299 4.0\n",
      "316 3.557737863271845 4.0\n",
      "356 3.126746659571524 3.0\n",
      "329 4.482782431144655 5.0\n",
      "480 4.865735692986987 4.0\n",
      "434 3.597178995740522 4.0\n",
      "10 4.0 4.0\n",
      "Normal RMSE: 0.28 Timebin RMSE:0.3                     Normal Threshold Acc: 90% Timebin Threshold Acc: 100%\n",
      "6365 4.3392246771883425 3.5\n",
      "2628 3.703100302627973 4.5\n",
      "1210 5.000000000000001 5.0\n",
      "33493 3.9507485190210443 5.0\n",
      "44191 4.5 5.0\n",
      "2028 4.502085233480058 5.0\n",
      "5445 4.04530839601086 4.0\n",
      "5378 3.357531868884848 4.0\n",
      "32587 4.737624865551133 5.0\n",
      "2571 4.607692956190557 4.0\n",
      "Normal RMSE: 0.025 Timebin RMSE:0.42                     Normal Threshold Acc: 100% Timebin Threshold Acc: 80%\n",
      "543 0 2.0\n",
      "475 0 5.0\n",
      "491 0 3.0\n",
      "596 0 3.0\n",
      "234 0 3.0\n",
      "494 0 3.0\n",
      "532 0 3.0\n",
      "50872 0 3.5\n",
      "55820 0 4.5\n",
      "50 4.722854240574221 4.5\n",
      "6016 5.0 5.0\n",
      "858 4.098855206703844 3.0\n",
      "1221 3.712386078803412 3.0\n",
      "5618 3.8335698992237655 3.0\n",
      "48394 1.5404558481518682 2.0\n",
      "2329 0 4.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.42                     Normal Threshold Acc: 57% Timebin Threshold Acc: 50%\n",
      "2683 0 4.0\n",
      "2706 0 5.0\n",
      "541 4.930677686204172 5.0\n",
      "2571 5.000000000000001 5.0\n",
      "1196 4.943222908225615 5.0\n",
      "1200 4.869859637159478 5.0\n",
      "1206 0 1.0\n",
      "1240 4.0555386559133915 5.0\n",
      "Normal RMSE: 1.6 Timebin RMSE:0.2                     Normal Threshold Acc: 100% Timebin Threshold Acc: 80%\n",
      "104 0 1.0\n",
      "653 0 2.0\n",
      "784 0 1.0\n",
      "3147 0 5.0\n",
      "79132 0 5.0\n",
      "116797 0 5.0\n",
      "112552 0 5.0\n",
      "2959 0 5.0\n",
      "91529 5.0 5.0\n",
      "Normal RMSE: 0.001 Timebin RMSE:0.001                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "527 5.0 4.0\n",
      "1193 4.77757339559513 5.0\n",
      "1732 4.819995627552742 5.0\n",
      "7147 3.09244723614093 3.5\n",
      "5418 4.187677478481594 4.5\n",
      "16 4.259338937471693 4.5\n",
      "223 0 4.5\n",
      "2542 0 4.5\n",
      "7438 4.213994532128972 4.5\n",
      "6874 4.812493769412455 4.5\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.25                     Normal Threshold Acc: 90% Timebin Threshold Acc: 87%\n",
      "1 4.693706082449214 4.0\n",
      "1022 5.0 4.0\n",
      "2078 2.6134779336441203 2.0\n",
      "2355 3.5 4.0\n",
      "364 4.5873643128274155 5.0\n",
      "2087 3.7255487989607743 3.0\n",
      "3034 3.4602889363815685 3.0\n",
      "596 3.588102915573283 3.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.34                     Normal Threshold Acc: 100% Timebin Threshold Acc: 75%\n",
      "30793 2.5 1.5\n",
      "49530 4.0 3.5\n",
      "3717 0 2.0\n",
      "4018 2.9999999999999996 2.0\n",
      "69757 3.5 4.0\n",
      "Normal RMSE: 0.025 Timebin RMSE:0.62                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "344 2.5 2.0\n",
      "1097 1.5000000000000002 2.0\n",
      "1 2.5 3.0\n",
      "Normal RMSE: 0.28 Timebin RMSE:0.25                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n",
      "318 4.518337647951644 5.0\n",
      "50 4.5270423755409555 4.5\n",
      "593 4.423449331478812 4.0\n",
      "296 4.602277116857302 4.5\n",
      "30793 2.000596202446391 2.5\n",
      "1221 4.724740970172213 5.0\n",
      "34405 0 3.5\n",
      "30749 4.0 3.5\n",
      "8784 4.5 4.0\n",
      "Normal RMSE: 4.0 Timebin RMSE:0.19                     Normal Threshold Acc: 62% Timebin Threshold Acc: 100%\n",
      "79132 0 3.0\n",
      "2571 4.276273868619416 3.5\n",
      "4226 4.40791057690601 4.5\n",
      "260 3.845819516135455 3.0\n",
      "745 4.108226255011993 4.0\n",
      "1252 4.702978082836864 4.5\n",
      "1213 4.2599564008856 3.5\n",
      "1136 4.591498279156513 4.0\n",
      "593 3.8066278157246254 3.0\n",
      "1196 3.3739098246296404 3.0\n",
      "Normal RMSE: 0.22 Timebin RMSE:0.5                     Normal Threshold Acc: 87% Timebin Threshold Acc: 77%\n",
      "356 4.857768339034367 5.0\n",
      "150 4.5893702353387225 4.0\n",
      "282 4.0 4.0\n",
      "454 4.0 4.0\n",
      "529 0 3.0\n",
      "1097 0 4.0\n",
      "593 5.0 5.0\n",
      "296 4.408348331972376 5.0\n",
      "350 3.700969524962029 3.0\n",
      "Normal RMSE: 0.042 Timebin RMSE:0.11                     Normal Threshold Acc: 100% Timebin Threshold Acc: 85%\n",
      "2329 4.1852564784602055 5.0\n",
      "293 4.459107196793892 4.5\n",
      "4226 4.368987714706212 4.5\n",
      "296 4.773316486868139 4.5\n",
      "58559 4.067591634996434 4.0\n",
      "1089 4.63047426180122 4.5\n",
      "7361 4.635210460362167 4.5\n",
      "1222 4.313619617742295 5.0\n",
      "858 4.284768514193344 4.0\n",
      "48394 4.054829429797381 3.5\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.2                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "3033 0 3.0\n",
      "431 0 3.5\n",
      "4963 0 3.5\n",
      "780 4.174186845620184 4.0\n",
      "25 4.298916363223321 4.0\n",
      "62 2.9999999999999996 3.0\n",
      "95 3.1588065135817027 3.0\n",
      "141 4.076061609903376 5.0\n",
      "648 3.438194951660444 4.0\n",
      "6 4.54139692261862 4.0\n",
      "36 3.97617622453352 4.0\n",
      "608 4.582722552119485 4.0\n",
      "733 3.8981625175000856 4.0\n",
      "Normal RMSE: 0.17 Timebin RMSE:0.2                     Normal Threshold Acc: 88% Timebin Threshold Acc: 90%\n",
      "493 0 3.0\n",
      "1721 0 5.0\n",
      "529 4.0 5.0\n",
      "1784 0 5.0\n",
      "318 4.405591866306022 4.0\n",
      "593 4.432143616168968 5.0\n",
      "1704 4.556717862545839 4.0\n",
      "36 4.074100763521568 4.0\n",
      "1358 4.0 4.0\n",
      "Normal RMSE: 0.35 Timebin RMSE:0.29                     Normal Threshold Acc: 80% Timebin Threshold Acc: 100%\n",
      "377 2.643522330648755 3.0\n",
      "410 2.696458305936696 3.0\n",
      "500 3.9766099979709644 4.0\n",
      "19 3.038888975139984 3.0\n",
      "317 4.0 5.0\n",
      "21 3.435727911471353 3.0\n",
      "586 2.0065709068135282 3.0\n",
      "587 3.08117969704428 3.0\n",
      "2 0 5.0\n",
      "141 0 4.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.34                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n",
      "786 0 2.0\n",
      "2571 0 5.0\n",
      "293 0 5.0\n",
      "1 4.65186830559572 4.5\n",
      "3114 4.314938331884644 4.0\n",
      "1968 4.205027642475918 4.0\n",
      "6377 4.59315031306874 5.0\n",
      "48738 4.500000000000001 4.5\n",
      "1704 4.543171645142685 4.0\n",
      "4886 4.36298684959155 4.0\n",
      "4306 4.208565774755192 4.0\n",
      "8665 4.095575508483252 4.0\n",
      "8961 4.871993571067313 4.5\n",
      "Normal RMSE: 0.16 Timebin RMSE:0.12                     Normal Threshold Acc: 87% Timebin Threshold Acc: 100%\n",
      "5010 4.0 3.5\n",
      "50872 4.0 4.5\n",
      "5459 4.0 4.0\n",
      "3717 3.5 3.5\n",
      "Normal RMSE: 0.75 Timebin RMSE:0.12                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "527 4.806674534100941 3.5\n",
      "1197 4.358695029586611 5.0\n",
      "2329 4.3069818835086675 3.5\n",
      "1265 4.096443406338513 3.5\n",
      "2502 0 2.5\n",
      "6539 4.350468556187056 4.5\n",
      "68954 4.079237075090586 5.0\n",
      "6377 4.480292774535433 5.0\n",
      "4306 4.204832066999304 5.0\n",
      "Normal RMSE: 0.3 Timebin RMSE:0.75                     Normal Threshold Acc: 80% Timebin Threshold Acc: 100%\n",
      "593 4.558329853966248 4.0\n",
      "608 3.04891673396043 3.0\n",
      "344 2.4999999999999996 2.0\n",
      "1097 1.6999254680830795 2.0\n",
      "1682 4.0 4.0\n",
      "Normal RMSE: 0.16 Timebin RMSE:0.15                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n",
      "434 3.9131581047787143 4.0\n",
      "1 4.584726457472067 5.0\n",
      "185 4.198217833379374 4.0\n",
      "208 3.27250307181902 3.0\n",
      "253 3.4470134323246437 4.0\n",
      "593 4.09547467718187 5.0\n",
      "288 2.0908128657237754 3.0\n",
      "380 4.0 5.0\n",
      "457 4.448990493688318 5.0\n",
      "110 4.854522638205019 5.0\n",
      "Normal RMSE: 0.62 Timebin RMSE:0.4                     Normal Threshold Acc: 66% Timebin Threshold Acc: 90%\n",
      "3175 5.0 4.0\n",
      "2907 5.0 5.0\n",
      "2706 5.0 5.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.33                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "590 3.8982635529497704 4.0\n",
      "153 3.539242885763361 3.0\n",
      "165 5.000000000000003 5.0\n",
      "344 5.0 5.0\n",
      "593 0 5.0\n",
      "231 5.000000000000001 5.0\n",
      "349 4.560967157251733 4.0\n",
      "457 3.516989597834777 4.0\n",
      "292 4.108824919361507 4.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.094                     Normal Threshold Acc: 85% Timebin Threshold Acc: 62%\n",
      "122882 2.5 2.5\n",
      "2329 4.145982896677494 4.0\n",
      "64614 3.4999999999999996 3.5\n",
      "296 4.90702665469316 4.0\n",
      "7361 4.434795106772605 5.0\n",
      "48780 3.184567899412151 3.0\n",
      "68157 3.5000000000000004 3.5\n",
      "48394 3.0 3.0\n",
      "109374 3.33495568099122 3.0\n",
      "4973 4.0 4.0\n",
      "Normal RMSE: 0.083 Timebin RMSE:0.15                     Normal Threshold Acc: 100% Timebin Threshold Acc: 90%\n",
      "173 0 3.0\n",
      "527 0 3.0\n",
      "586 0 3.0\n",
      "122926 0 5.0\n",
      "134130 4.0 4.5\n",
      "593 0 4.5\n",
      "122904 4.0 3.5\n",
      "Normal RMSE: 0.54 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "592 0 3.0\n",
      "780 0 4.0\n",
      "1270 0 5.0\n",
      "3114 2.9666422999413866 3.0\n",
      "3793 4.091216451960798 3.5\n",
      "5945 3.5 5.0\n",
      "6711 0 5.0\n",
      "153 0 4.0\n",
      "32 4.07968412745935 5.0\n",
      "7361 0 4.0\n",
      "4963 4.452889858242677 4.0\n",
      "Normal RMSE: 1.1 Timebin RMSE:0.75                     Normal Threshold Acc: 66% Timebin Threshold Acc: 100%\n",
      "1198 3.6091508175904425 2.0\n",
      "1196 4.825885183492029 4.5\n",
      "1197 3.5 3.0\n",
      "527 4.70903261643763 4.0\n",
      "6016 4.88107142017902 4.0\n",
      "296 4.999999999999999 4.0\n",
      "7153 4.26615669576892 4.0\n",
      "1193 4.775110573703885 5.0\n",
      "1206 4.760915746761737 5.0\n",
      "778 4.945013385296883 4.0\n",
      "Normal RMSE: 1.1 Timebin RMSE:0.62                     Normal Threshold Acc: 71% Timebin Threshold Acc: 80%\n",
      "58559 4.893575996980339 5.0\n",
      "5952 4.830223462651042 5.0\n",
      "4993 5.000000000000001 5.0\n",
      "79132 5.0 5.0\n",
      "112852 0 5.0\n",
      "1200 4.601916723958493 3.0\n",
      "Normal RMSE: 0.062 Timebin RMSE:0.45                     Normal Threshold Acc: 87% Timebin Threshold Acc: 60%\n",
      "527 4.710673657232425 5.0\n",
      "2959 4.241031633830074 4.5\n",
      "1203 4.7963580231416945 5.0\n",
      "7153 2.8248122299651337 2.5\n",
      "5952 3.483927668490132 3.0\n",
      "6874 3.595747656975284 4.5\n",
      "5349 1.351127878961365 3.0\n",
      "Normal RMSE: 0.82 Timebin RMSE:0.61                     Normal Threshold Acc: 85% Timebin Threshold Acc: 100%\n",
      "1370 2.0 2.0\n",
      "1377 4.0 3.0\n",
      "1597 2.0 1.0\n",
      "2023 3.0000000000000004 5.0\n",
      "648 0 1.0\n",
      "329 2.0 1.0\n",
      "Normal RMSE: 1.8 Timebin RMSE:1.4                     Normal Threshold Acc: 66% Timebin Threshold Acc: 60%\n",
      "1263 0 5.0\n",
      "3681 0 5.0\n",
      "2657 3.2711047441531877 3.5\n",
      "1320 0 4.0\n",
      "1250 5.0 5.0\n",
      "2081 3.09109507471633 3.0\n",
      "3623 2.3376888194072545 0.5\n",
      "903 4.24767958467212 3.5\n",
      "1148 3.5 4.5\n",
      "Normal RMSE: 1.9 Timebin RMSE:0.88                     Normal Threshold Acc: 77% Timebin Threshold Acc: 83%\n",
      "1199 5.0 5.0\n",
      "924 0 5.0\n",
      "1206 5.000000000000001 5.0\n",
      "1258 5.0 5.0\n",
      "7153 5.0 4.5\n",
      "4993 5.0 4.5\n",
      "4226 0 4.5\n",
      "2987 0 4.5\n",
      "Normal RMSE: 0.083 Timebin RMSE:0.1                     Normal Threshold Acc: 100% Timebin Threshold Acc: 80%\n",
      "1544 0 3.0\n",
      "903 0 4.0\n",
      "1527 3.392219195141941 4.0\n",
      "260 0 4.0\n",
      "858 0 5.0\n",
      "Normal RMSE: 0.62 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 0%\n",
      "2028 4.0 4.5\n",
      "2571 5.0 4.5\n",
      "47099 5.0 4.5\n",
      "Normal RMSE: 0.16 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "116797 4.817802178674794 4.5\n",
      "74458 3.5000000000000004 4.0\n",
      "112556 4.0 4.0\n",
      "109487 4.5 5.0\n",
      "48780 0 5.0\n",
      "106782 4.0 4.0\n",
      "48516 0 4.5\n",
      "99114 4.597004152057941 5.0\n",
      "84152 4.5 4.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.18                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "1240 3.913282470157811 4.0\n",
      "1965 0 2.0\n",
      "1270 0 2.0\n",
      "2011 2.6526174876786484 2.0\n",
      "2012 2.4789262315179723 2.0\n",
      "2 1.0608621666876692 1.0\n",
      "589 0 3.0\n",
      "1097 4.0675773603214065 4.0\n",
      "1129 0 2.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.1                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n",
      "553 0 4.0\n",
      "186 0 3.0\n",
      "48 2.734059837071216 3.0\n",
      "193 1.0 3.0\n",
      "364 2.0 3.0\n",
      "454 4.0 4.0\n",
      "273 1.8784390685653776 3.0\n",
      "367 2.0 3.0\n",
      "163 1.6197847251396797 3.0\n",
      "Normal RMSE: 0.86 Timebin RMSE:1.4                     Normal Threshold Acc: 71% Timebin Threshold Acc: 100%\n",
      "317 0 2.0\n",
      "527 0 4.0\n",
      "7143 0 3.5\n",
      "5816 0 3.5\n",
      "6378 0 3.5\n",
      "8361 0 2.5\n",
      "4446 0 3.0\n",
      "7153 4.688116419390108 3.5\n",
      "750 4.544222026396923 4.5\n",
      "109487 3.4108764395874447 3.5\n",
      "47 4.999999999999999 5.0\n",
      "356 5.0 5.0\n",
      "110 4.377543355532667 3.5\n",
      "109374 4.5 5.0\n",
      "30749 0 5.0\n",
      "91529 4.0 4.0\n",
      "55820 3.7110566277188743 4.0\n",
      "Normal RMSE: 0.42 Timebin RMSE:0.28                     Normal Threshold Acc: 100% Timebin Threshold Acc: 88%\n",
      "150 2.9641710016802794 3.0\n",
      "296 4.575084166324915 5.0\n",
      "380 4.651399431473504 5.0\n",
      "590 3.4985801480777163 3.0\n",
      "592 3.4661160697821334 3.0\n",
      "153 4.687908667104631 4.0\n",
      "165 3.50915441991283 3.0\n",
      "344 3.9129314755863938 4.0\n",
      "457 3.31545151445877 3.0\n",
      "588 3.4192105755757902 3.0\n",
      "Normal RMSE: 1.4 Timebin RMSE:0.2                     Normal Threshold Acc: 55% Timebin Threshold Acc: 90%\n",
      "349 3.7449198142649105 4.0\n",
      "329 3.056136275094215 3.0\n",
      "457 4.458818920217977 5.0\n",
      "593 4.207262445959172 4.0\n",
      "292 3.8676650057249176 4.0\n",
      "356 4.601264273190218 5.0\n",
      "161 3.514913797826788 3.0\n",
      "480 4.557826592239526 4.0\n",
      "208 3.3499275119584384 3.0\n",
      "339 4.330948097123239 4.0\n",
      "Normal RMSE: 0.39 Timebin RMSE:0.17                     Normal Threshold Acc: 77% Timebin Threshold Acc: 90%\n",
      "48780 3.2493858175757966 3.5\n",
      "68157 4.705296330908257 4.0\n",
      "69844 0 4.5\n",
      "5618 0 3.5\n",
      "49272 4.857482535385095 4.5\n",
      "54001 4.382063723563763 4.0\n",
      "44191 4.0 3.5\n",
      "2959 4.6406561997292135 4.0\n",
      "593 0 4.0\n",
      "Normal RMSE: 0.33 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 83%\n",
      "318 4.689379155209812 4.0\n",
      "527 4.442653958433567 3.5\n",
      "1197 4.677777725851048 5.0\n",
      "2329 0 3.5\n",
      "1265 4.0 3.5\n",
      "2502 0 2.5\n",
      "6539 0 4.5\n",
      "68954 4.289410176909219 5.0\n",
      "Normal RMSE: 0.31 Timebin RMSE:0.4                     Normal Threshold Acc: 77% Timebin Threshold Acc: 100%\n",
      "21 3.000000000000001 3.0\n",
      "377 3.0000000000000004 3.0\n",
      "500 2.842166236832476 3.0\n",
      "39 2.1019361112663204 3.0\n",
      "50 4.965188208566462 4.0\n",
      "586 2.879327671778908 3.0\n",
      "32 4.4155600347621355 4.0\n",
      "527 4.999999999999999 3.0\n",
      "587 2.93451842302177 3.0\n",
      "597 2.429507160108061 3.0\n",
      "Normal RMSE: 0.35 Timebin RMSE:0.65                     Normal Threshold Acc: 60% Timebin Threshold Acc: 90%\n",
      "3869 0 4.0\n",
      "356 4.179479414070231 3.0\n",
      "593 4.5019000848719175 3.0\n",
      "260 4.066009175386631 3.5\n",
      "150 4.517774209627684 4.0\n",
      "1 4.295446785845587 4.0\n",
      "780 3.9690169089027387 3.5\n",
      "Normal RMSE: 0.33 Timebin RMSE:0.71                     Normal Threshold Acc: 100% Timebin Threshold Acc: 66%\n",
      "919 4.3504336457581 4.5\n",
      "19 2.185477595622061 1.0\n",
      "2683 3.5966207307826448 3.5\n",
      "368 0 4.5\n",
      "1923 0 3.5\n",
      "1225 3.150094016247149 3.5\n",
      "1220 3.0 3.0\n",
      "235 2.661776154394036 1.0\n",
      "Normal RMSE: 1.2 Timebin RMSE:0.58                     Normal Threshold Acc: 100% Timebin Threshold Acc: 83%\n",
      "296 0 3.0\n",
      "380 3.0 3.0\n",
      "457 2.7362868645919556 2.0\n",
      "593 0 2.0\n",
      "318 0 3.0\n",
      "10 2.730512901981947 2.0\n",
      "339 3.0000000000000004 2.0\n",
      "300 0 3.0\n",
      "225 0 3.0\n",
      "367 0 3.0\n",
      "Normal RMSE: 0.78 Timebin RMSE:0.38                     Normal Threshold Acc: 60% Timebin Threshold Acc: 100%\n",
      "1206 0 5.0\n",
      "4878 0 4.0\n",
      "924 0 5.0\n",
      "1517 3.7289799701323574 4.0\n",
      "2396 0 3.0\n",
      "1917 2.7886116207913174 2.0\n",
      "141 3.6494010421614584 4.0\n",
      "95 2.5 3.0\n",
      "1784 0 3.5\n",
      "50 3.567646218954655 4.0\n",
      "1704 4.507379985511881 5.0\n",
      "Normal RMSE: 0.33 Timebin RMSE:0.38                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "480 3.837561417476271 4.5\n",
      "589 4.0690597756765845 3.5\n",
      "1 2.6653863912096782 2.5\n",
      "780 2.9588326956496243 1.5\n",
      "590 3.7390123460156786 4.5\n",
      "1210 3.9615306251937734 3.5\n",
      "260 4.0449406683030915 3.5\n",
      "Normal RMSE: 0.45 Timebin RMSE:0.61                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "480 0 5.0\n",
      "2948 3.8604874966300655 3.0\n",
      "2353 4.0 5.0\n",
      "380 3.549650866757958 3.0\n",
      "3256 4.0 4.0\n",
      "1220 0 3.0\n",
      "3635 0 2.0\n",
      "Normal RMSE: 1.0 Timebin RMSE:0.56                     Normal Threshold Acc: 100% Timebin Threshold Acc: 50%\n",
      "1136 4.999999999999999 5.0\n",
      "1244 4.0 3.0\n",
      "2788 3.5469241809648113 3.0\n",
      "3363 4.845266275769873 5.0\n",
      "Normal RMSE: 0.25 Timebin RMSE:0.31                     Normal Threshold Acc: 100% Timebin Threshold Acc: 50%\n",
      "1321 3.500000000000001 2.5\n",
      "1196 5.0 4.0\n",
      "1136 5.000000000000001 4.0\n",
      "1197 4.5 4.0\n",
      "260 4.500000000000001 4.5\n",
      "Normal RMSE: 0.94 Timebin RMSE:0.65                     Normal Threshold Acc: 87% Timebin Threshold Acc: 60%\n",
      "45722 4.287436066182749 4.0\n",
      "1196 4.754258213124369 5.0\n",
      "2959 4.999999999999999 4.5\n",
      "4993 4.313378285344043 4.0\n",
      "736 2.3404123964301906 3.5\n",
      "1073 4.888805062546582 4.0\n",
      "47 4.698855740679025 4.5\n",
      "648 3.416710682799274 3.5\n",
      "2329 4.385408891673925 5.0\n",
      "Normal RMSE: 0.075 Timebin RMSE:0.33                     Normal Threshold Acc: 90% Timebin Threshold Acc: 77%\n",
      "30749 0 4.5\n",
      "47 4.185148945240469 3.5\n",
      "356 4.051149582063284 4.0\n",
      "480 3.520415404721402 4.0\n",
      "457 3.0000000000000004 3.0\n",
      "150 2.0 1.0\n",
      "589 4.38713521007663 4.0\n",
      "Normal RMSE: 0.083 Timebin RMSE:0.29                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "4995 0 3.0\n",
      "4027 0 3.0\n",
      "3481 0 3.5\n",
      "1370 0 3.5\n",
      "1047 0 2.0\n",
      "2617 0 3.5\n",
      "165 3.758982896136668 4.0\n",
      "50 4.707869284182399 4.5\n",
      "1196 4.4674704501910965 4.0\n",
      "8961 3.9045076153955227 4.0\n",
      "8970 3.823563937616482 2.5\n",
      "8957 3.2659197489426575 4.0\n",
      "8636 4.2275657447924635 4.5\n",
      "6333 4.090369333723016 4.0\n",
      "Normal RMSE: 0.5 Timebin RMSE:0.38                     Normal Threshold Acc: 100% Timebin Threshold Acc: 75%\n",
      "111 5.0 4.5\n",
      "909 0 4.5\n",
      "608 0 4.5\n",
      "908 4.0 5.0\n",
      "904 0 4.5\n",
      "Normal RMSE: 0.12 Timebin RMSE:0.62                     Normal Threshold Acc: 100% Timebin Threshold Acc: 100%\n",
      "1258 4.706851522175458 4.0\n",
      "1653 0 4.5\n",
      "4993 4.690288799733527 4.5\n",
      "1213 4.443759546906388 4.0\n",
      "4878 4.6481413758048555 4.0\n",
      "7438 4.317649753997665 4.0\n",
      "7153 4.393236136528024 4.5\n",
      "Normal RMSE: 0.97 Timebin RMSE:0.17                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n",
      "55765 0 2.5\n",
      "3000 3.9224462045196 3.0\n",
      "296 4.676190762713565 4.5\n",
      "541 4.819775468017434 4.5\n",
      "1617 3.917199862820474 4.0\n",
      "1089 4.79349947693985 4.5\n",
      "1214 4.0 4.0\n",
      "Normal RMSE: 0.3 Timebin RMSE:0.25                     Normal Threshold Acc: 100% Timebin Threshold Acc: 83%\n",
      "1831 0 0.5\n",
      "1882 0 2.0\n",
      "2949 0 3.0\n",
      "454 4.241983641775102 4.0\n",
      "593 4.999999999999999 5.0\n",
      "296 4.908636662393465 5.0\n",
      "350 0 3.0\n",
      "161 3.7164340081557787 3.0\n",
      "185 3.489903829729353 3.0\n",
      "Normal RMSE: 0.11 Timebin RMSE:0.1                     Normal Threshold Acc: 85% Timebin Threshold Acc: 80%\n",
      "25 4.509429666322551 5.0\n",
      "648 3.470821532033435 3.0\n",
      "3 3.0 3.0\n",
      "36 4.0 4.0\n",
      "608 5.0 5.0\n",
      "14 4.0 4.0\n",
      "58 4.624170811765935 5.0\n",
      "786 2.9999999999999996 4.0\n",
      "762 0 2.0\n",
      "628 0 3.0\n",
      "Normal RMSE: 0.075 Timebin RMSE:0.22                     Normal Threshold Acc: 100% Timebin Threshold Acc: 87%\n",
      "1580 3.0 3.0\n",
      "91529 4.0 3.5\n",
      "48516 4.5 4.5\n",
      "Normal RMSE: 0.5 Timebin RMSE:0.083                     Normal Threshold Acc: 75% Timebin Threshold Acc: 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timebin_similarity.analize_timebin_prediction(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin = timebin_similarity.get_timebin2(449, 0, 10)\n",
    "timebin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = t.get_k_neighbours(449, k=None)   # Get all neighbours of the timebin using classic way\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = df.index.values\n",
    "neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['correlation'] > 0.2]    # Filter low correlation neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin_similarity.get_neighbour_timebins(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timebin_similarity.get_most_similar_timebins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbour_timebins_with_the_movie(self, neighbour_id:int, movie_id:int)->list:\n",
    "    \"\"\"\n",
    "    Given a neighbour_id, take the all the timebins of this neighbour which includes the given movie.\n",
    "    \"\"\"\n",
    "    # Start by taking all movies watched by the neighbour\n",
    "    all_movies_watched = self.get_movies_watched(neighbour_id)\n",
    "    n_movies = len(all_movies_watched)\n",
    "    neighbour_timebins = list()\n",
    "    \n",
    "    # For each timebin_size\n",
    "    for timebin_size in range(self.neighbour_min_s, self.neighbour_max_s, self.neighbour_step_size):\n",
    "        # Traverse the all movies by taking 'timebin_size' piece of ratings per loop\n",
    "        for i in range(0, n_movies, timebin_size):\n",
    "            timebin = all_movies_watched.iloc[i:i+timebin_size]\n",
    "            # Take only timebins which includes this movie\n",
    "            if not (movie_id in timebin.index):\n",
    "                continue\n",
    "            # Insert the timebin, its index i, and its size timebin_size into the list as a tuple\n",
    "            neighbour_timebins.append(  (timebin, i, timebin_size)  )\n",
    "    return neighbour_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin_neighbours_with_the_movie(self, user_id:int, timebin_i, timebin_size, i):\n",
    "    # Recreate the user timebin using its identifiers\n",
    "    timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "    movie_id = timebin.index[i]\n",
    "    \n",
    "    # Count number of common ratings with other users\n",
    "    userlist = [0 for i in range(611)]\n",
    "    for movie_id in timebin.index.values.tolist():\n",
    "        users_who_watched = ratings.loc[(ratings['item_id'] == movie_id)][['user_id']].values.tolist()\n",
    "        for user_who_watched in users_who_watched:\n",
    "            userlist[user_who_watched[0]] += 1\n",
    "\n",
    "    # save as neighbour, if common rating count greater than k and given rating to the movie index at i\n",
    "    neighbour_id_list = []\n",
    "    for j in range(0, 611):\n",
    "        if (userlist[j] > self.k) and \n",
    "           (self.trainset_movie.get_movie_rating(user_id=j, movie_id=movie_id) != 0) and \n",
    "           (j != user_id):\n",
    "            neighbour_id_list.append(j)\n",
    "    \n",
    "    return neighbour_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_timebins(self, user_id, timebin_i, timebin_size, i = None):\n",
    "    \"\"\"\n",
    "    Get Neighbour Timebins\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the user timebin\n",
    "    if i is not None:\n",
    "        timebin = self.get_timebin3(user_id, timebin_i, timebin_size, i)\n",
    "    else:\n",
    "        timebin = self.get_timebin2(user_id, timebin_i, timebin_size)\n",
    "\n",
    "    time_constraint = TimeConstraint(end_dt=timebin.iloc[len(timebin)-1]['timestamp'])\n",
    "    # Set the self.timebin as the timebin of interest with required details for correlation calculations\n",
    "    self.timebin = timebin\n",
    "    self.user_id = user_id\n",
    "    self.timebin_user_avg_rating = self.trainset_user.get_user_avg_at(user_id, time_constraint.end_dt)\n",
    "\n",
    "    # Neighbours contains users who has rated self.k movies in common\n",
    "    neighbours = self.get_timebin_neighbours(user_id, timebin_i, timebin_size, i)\n",
    "    data = list()\n",
    "\n",
    "    # For Each neighbour\n",
    "\n",
    "    for neighbour_id in neighbours:\n",
    "\n",
    "        # neighbour can not be user himself! results in perfect predictions.d :)\n",
    "        if neighbour_id == self.user_id:\n",
    "            continue\n",
    "\n",
    "        neighbour_timebins = self.get_neighbour_timebins(neighbour_id) \n",
    "        neighbour_avg_rating = self.trainset_user.get_user_avg_at(neighbour_id, time_constraint.end_dt)\n",
    "\n",
    "        # For each neighbour timebin, calculate pearson between the timebin and neighbour timebin \n",
    "        for neighbour_timebin, timebin_i, timebin_size in neighbour_timebins:\n",
    "            # Filter unrelated movie ratings and only keep common movie ratings\n",
    "\n",
    "            merged = neighbour_timebin.merge(self.timebin, on='item_id')\n",
    "            common_elements = len(merged)\n",
    "\n",
    "            # If less than self.r movies in common rated in the neighbour_timebin, dont process this timebin\n",
    "            if common_elements < self.r:\n",
    "                continue\n",
    "\n",
    "            # Calculate Pearson Correlation between neighbour timebin and self.timebin\n",
    "            corr = self.find_timebin_corr(merged, neighbour_avg_rating)\n",
    "\n",
    "            # Dont include the neighbour timebin if corr is invalid or less than corr_threshold\n",
    "            if math.isnan(corr) or corr < self.corr_threshold:                     \n",
    "                continue\n",
    "\n",
    "            binsize_in_days = TimebinSimilarity.get_timebin_size(\n",
    "                                TimeConstraint(start_dt=neighbour_timebin.iloc[0]['timestamp'], \n",
    "                                               end_dt=neighbour_timebin.iloc[len(neighbour_timebin)-1]['timestamp']))\n",
    "\n",
    "            data.append( (neighbour_id, common_elements, corr, timebin_i, timebin_size, binsize_in_days) )\n",
    "\n",
    "    return pd.DataFrame(data, columns=['neighbour_id', 'n_common','pearson_corr', 'timebin_i', 'timebin_size', 'timebin_size_in_days'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = timebin_similarity.get_movies_watched(449)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1090 in dd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.trainset_movie.get_movie_rating(user_id=440, movie_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
